{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ”¥ Using GPU: {gpu_name}\")\n",
    "    torch.backends.cudnn.benchmark = True  # ì…ë ¥ í¬ê¸° ê³ ì •ì´ë©´ ë” ë¹ ë¦„\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ GPU not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os, random, numpy as np, torch\n",
    "\n",
    "# ------------------------\n",
    "# Reproducibility & GPU Optimization\n",
    "# ------------------------\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# âš™ï¸ cuDNN settings\n",
    "torch.backends.cudnn.deterministic = False  # Trueë©´ ì¬í˜„ì„±â†‘, ì†ë„â†“\n",
    "torch.backends.cudnn.benchmark = True       # ì…ë ¥ í¬ê¸° ê³ ì •ì´ë©´ ì†ë„â†‘\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "# âš¡ Device check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ”¥ Using GPU: {gpu_name}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ Using CPU. (No CUDA detected)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_or_df, path, transform=None):\n",
    "        # csv ê²½ë¡œ(str) or DataFrame ëª¨ë‘ í—ˆìš©\n",
    "        if isinstance(csv_or_df, str):\n",
    "            self.df = pd.read_csv(csv_or_df).values\n",
    "        else:\n",
    "            self.df = csv_or_df.values\n",
    "\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert(\"RGB\"))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        return img, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for images, targets in pbar:\n",
    "        images, targets = images.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # âš¡ Mixed Precision Training\n",
    "        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        # âœ… backward (scaler ìˆì„ ë•Œì™€ ì—†ì„ ë•Œ ëª¨ë‘ ì§€ì›)\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    # Epoch metrics\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# âš¡ Device setting\n",
    "# ------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ”¥ Using GPU: {gpu_name}\")\n",
    "    torch.backends.cudnn.benchmark = True  # ì…ë ¥ í¬ê¸° ê³ ì •ì´ë©´ ì†ë„ â†‘\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ Using CPU. (No CUDA detected)\")\n",
    "\n",
    "# ------------------------\n",
    "# âš™ï¸ Data config\n",
    "# ------------------------\n",
    "data_path = \"../../../data/raw/\"\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§  Model config\n",
    "# ------------------------\n",
    "# ë¬¸ì„œ ë¶„ë¥˜ ì •í™•ë„ ìš°ì„  ì„¸íŒ… (ConvNeXt-Tiny)\n",
    "model_name = \"convnext_tiny.fb_in22k_ft_in1k\"  # ImageNet22k â†’ 1k fine-tuned ê°€ì¤‘ì¹˜ ì‚¬ìš©\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ“ˆ Training config (RTX 3090 ìµœì í™”)\n",
    "# ------------------------\n",
    "img_size = 384            # ë¬¸ì„œ ì´ë¯¸ì§€ë©´ 384~512 ì¶”ì²œ\n",
    "LR = 5e-4                 # ConvNeXt-Tinyì—ë„ ì˜ ë§ëŠ” ê°’\n",
    "EPOCHS = 15               # ì•½ê°„ ë” ê¸´ í•™ìŠµ ì¶”ì²œ (10 â†’ 15)\n",
    "BATCH_SIZE = 64           # ConvNeXtëŠ” EfficientNetë³´ë‹¤ ë©”ëª¨ë¦¬ ì¡°ê¸ˆ ë” ì”€\n",
    "num_workers = 8           # CPU ë³‘ë ¬ ì²˜ë¦¬ ê°•í™”\n",
    "pin_memory = True\n",
    "persistent_workers = True\n",
    "prefetch_factor = 4       # DataLoader ì„±ëŠ¥ ê°œì„ \n",
    "\n",
    "# ------------------------\n",
    "# ğŸ’¡ Notes\n",
    "# ------------------------\n",
    "# - ConvNeXt-TinyëŠ” êµ¬ì¡°ì ìœ¼ë¡œ EfficientNetë³´ë‹¤ ê¹Šê³  ë„“ì€ ëª¨ë¸ì´ë¼,\n",
    "#   GPU ì‚¬ìš©ëŸ‰ì€ ì•½ 1.5~2ë°° ë†’ì§€ë§Œ, ë¬¸ì„œ(í…ìŠ¤íŠ¸/ë„ì¥/ë ˆì´ì•„ì›ƒ) ë¶„ë¥˜ ì„±ëŠ¥ì´ í›¨ì”¬ ì¢‹ìŒ.\n",
    "# - AMP ì‚¬ìš© ì‹œ ì†ë„ëŠ” ê±°ì˜ ë™ì¼, ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ í¼.\n",
    "# - ëª¨ë¸ ë¡œë“œëŠ” ì•„ë˜ì²˜ëŸ¼ í•˜ë©´ ë¨:\n",
    "#     import timm\n",
    "#     model = timm.create_model(model_name, pretrained=True, num_classes=NUM_CLASSES)\n",
    "#     model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_85164/3393421690.py:21: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5, 20), p=0.5),\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§¾ Train Transform (Document-Optimized)\n",
    "# ------------------------\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "\n",
    "    # ì‚´ì§ì˜ ê¸°ìš¸ê¸° ë° ìŠ¤ì¼€ì¼ ë³€í™” (ìŠ¤ìº” ì˜¤ì°¨ í‰ë‚´)\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.01,\n",
    "        scale_limit=0.05,\n",
    "        rotate_limit=2,\n",
    "        p=0.3\n",
    "    ),\n",
    "\n",
    "    # ìŠ¤ìº” ë…¸ì´ì¦ˆ ë° ë¸”ëŸ¬ íš¨ê³¼ (ë¬¸ì„œ í’ˆì§ˆ ë‹¤ì–‘í™”)\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=3, p=0.5),\n",
    "        A.GaussNoise(var_limit=(5, 20), p=0.5),\n",
    "    ], p=0.2),\n",
    "\n",
    "    # ë°ê¸°Â·ëŒ€ë¹„ëŠ” ì‚´ì§ë§Œ ì¡°ì • (í°ì¹´/ìŠ¤ìºë„ˆ í¸ì°¨ ëŒ€ì‘)\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=0.05,\n",
    "        contrast_limit=0.05,\n",
    "        p=0.3\n",
    "    ),\n",
    "\n",
    "    # ëŒ€ë¹„ ì •ê·œí™” (ë¬¸ì„œ ê¸€ì ì„ ëª…í•˜ê²Œ)\n",
    "    A.CLAHE(clip_limit=2.0, p=0.2),\n",
    "\n",
    "    # ì •ê·œí™” (ImageNet ê¸°ì¤€ ìœ ì§€)\n",
    "    A.Normalize(\n",
    "        mean=(0.5, 0.5, 0.5),\n",
    "        std=(0.5, 0.5, 0.5)\n",
    "    ),\n",
    "\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§¾ Validation / Test Transform (Matching Style)\n",
    "# ------------------------\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.CLAHE(clip_limit=2.0, p=1.0),  # ë°ê¸° ëŒ€ë¹„ ì •ê·œí™” ì ìš©\n",
    "    A.Normalize(\n",
    "        mean=(0.5, 0.5, 0.5),\n",
    "        std=(0.5, 0.5, 0.5)\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1ï¸âƒ£ train.csv ë¡œë“œ\n",
    "full_df = pd.read_csv(\"../../../data/raw/train.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ train/val ë¶„ë¦¬ (stratifyë¡œ í´ë˜ìŠ¤ ê· í˜• ìœ ì§€)\n",
    "trn_df, val_df = train_test_split(\n",
    "    full_df, test_size=0.2, stratify=full_df['target'], random_state=42\n",
    ")\n",
    "\n",
    "# 3ï¸âƒ£ Dataset ì •ì˜\n",
    "trn_dataset = ImageDataset(trn_df, \"../../../data/raw/train/\", transform=trn_transform)\n",
    "val_dataset = ImageDataset(val_df, \"../../../data/raw/train/\", transform=tst_transform)\n",
    "tst_dataset = ImageDataset(\"../../../data/raw/sample_submission.csv\",\n",
    "                           \"../../../data/raw/test/\", transform=tst_transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Train loader\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Validation loader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor\n",
    ")\n",
    "\n",
    "# Test loader (inference ì „ìš©)\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85164/1904133478.py:61: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from timm.optim import create_optimizer_v2\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§  Load Model\n",
    "# ------------------------\n",
    "\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17,\n",
    "    in_chans=3,\n",
    "    drop_path_rate=0.1\n",
    ").to(device)\n",
    "\n",
    "# ê¸°ì¡´ head ì´ˆê¸°í™” í›„ ìƒˆë¡œ ì •ì˜\n",
    "in_features = model.num_features  # â† get_classifier()ë³´ë‹¤ ì•ˆì „\n",
    "model.head = nn.Sequential(\n",
    "    nn.AdaptiveAvgPool2d(1),  # (B, C, H, W) â†’ (B, C, 1, 1)\n",
    "    nn.Flatten(1),            # (B, C, 1, 1) â†’ (B, C)\n",
    "    nn.LayerNorm(in_features),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(in_features, 17)\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ’¥ Loss Function\n",
    "# ------------------------\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# ------------------------\n",
    "# âš™ï¸ Optimizer (Lion)\n",
    "# ------------------------\n",
    "optimizer = create_optimizer_v2(\n",
    "    model,\n",
    "    opt='lion',\n",
    "    lr=3e-4,            # ì‚´ì§ ë‚®ì¶° ì•ˆì •ì  í•™ìŠµ\n",
    "    weight_decay=1e-4,\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ“ˆ Scheduler (OneCycleLR)\n",
    "# ------------------------\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=3e-4,\n",
    "    steps_per_epoch=len(trn_loader),\n",
    "    epochs=EPOCHS,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy='cos',\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# âš¡ AMP Scaler\n",
    "# ------------------------\n",
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss, preds_list, targets_list = 0.0, [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Validating\", leave=False)\n",
    "    for images, targets in pbar:\n",
    "        images, targets = images.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "        with torch.amp.autocast(\"cuda\"):\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "        targets_list.extend(targets.cpu().numpy())\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average=\"macro\")\n",
    "\n",
    "    return {\"val_loss\": val_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}\n",
    "\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler=None, scheduler=None):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # âš¡ Mixed Precision\n",
    "        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # âš™ï¸ OneCycleLRì€ iteration ë‹¨ìœ„ë¡œ í˜¸ì¶œí•´ì•¼ í•¨\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "best_f1 = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:182: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1/15]\n",
      "Train | Loss: 2.7537 | Acc: 0.1686 | F1: 0.1529\n",
      "Valid | Loss: 1.8748 | Acc: 0.5318 | F1: 0.4280\n",
      "âœ… Best model updated! (F1: 0.4280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2/15]\n",
      "Train | Loss: 1.8670 | Acc: 0.5016 | F1: 0.4556\n",
      "Valid | Loss: 1.2616 | Acc: 0.7197 | F1: 0.6483\n",
      "âœ… Best model updated! (F1: 0.6483)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 3/15]\n",
      "Train | Loss: 1.2272 | Acc: 0.7525 | F1: 0.7160\n",
      "Valid | Loss: 1.0633 | Acc: 0.8057 | F1: 0.7551\n",
      "âœ… Best model updated! (F1: 0.7551)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 4/15]\n",
      "Train | Loss: 1.0120 | Acc: 0.8265 | F1: 0.7991\n",
      "Valid | Loss: 0.9811 | Acc: 0.8217 | F1: 0.7829\n",
      "âœ… Best model updated! (F1: 0.7829)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 5/15]\n",
      "Train | Loss: 0.9107 | Acc: 0.8660 | F1: 0.8513\n",
      "Valid | Loss: 0.7870 | Acc: 0.9204 | F1: 0.9093\n",
      "âœ… Best model updated! (F1: 0.9093)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 6/15]\n",
      "Train | Loss: 0.8385 | Acc: 0.8988 | F1: 0.8863\n",
      "Valid | Loss: 0.7817 | Acc: 0.9076 | F1: 0.8934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 7/15]\n",
      "Train | Loss: 0.7711 | Acc: 0.9285 | F1: 0.9186\n",
      "Valid | Loss: 0.7573 | Acc: 0.9204 | F1: 0.9108\n",
      "âœ… Best model updated! (F1: 0.9108)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 8/15]\n",
      "Train | Loss: 0.7287 | Acc: 0.9465 | F1: 0.9425\n",
      "Valid | Loss: 0.6944 | Acc: 0.9586 | F1: 0.9546\n",
      "âœ… Best model updated! (F1: 0.9546)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 9/15]\n",
      "Train | Loss: 0.7052 | Acc: 0.9548 | F1: 0.9526\n",
      "Valid | Loss: 0.7009 | Acc: 0.9459 | F1: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10/15]\n",
      "Train | Loss: 0.6983 | Acc: 0.9597 | F1: 0.9574\n",
      "Valid | Loss: 0.6838 | Acc: 0.9554 | F1: 0.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 11/15]\n",
      "Train | Loss: 0.6824 | Acc: 0.9688 | F1: 0.9667\n",
      "Valid | Loss: 0.6875 | Acc: 0.9554 | F1: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 12/15]\n",
      "Train | Loss: 0.6675 | Acc: 0.9720 | F1: 0.9702\n",
      "Valid | Loss: 0.6751 | Acc: 0.9522 | F1: 0.9512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 13/15]\n",
      "Train | Loss: 0.6391 | Acc: 0.9836 | F1: 0.9830\n",
      "Valid | Loss: 0.6804 | Acc: 0.9490 | F1: 0.9469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 14/15]\n",
      "Train | Loss: 0.6373 | Acc: 0.9844 | F1: 0.9844\n",
      "Valid | Loss: 0.6745 | Acc: 0.9554 | F1: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_85164/4174820261.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 15/15]\n",
      "Train | Loss: 0.6385 | Acc: 0.9844 | F1: 0.9841\n",
      "Valid | Loss: 0.6738 | Acc: 0.9554 | F1: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 1ï¸âƒ£ Train (ì´ì œ schedulerëŠ” ë‚´ë¶€ì—ì„œ stepë¨)\n",
    "    train_metrics = train_one_epoch(trn_loader, model, optimizer, loss_fn, device, scaler, scheduler)\n",
    "\n",
    "    # 2ï¸âƒ£ Validation\n",
    "    val_metrics = validate(val_loader, model, loss_fn, device)\n",
    "\n",
    "    # 3ï¸âƒ£ Logging\n",
    "    print(f\"\\n[Epoch {epoch+1}/{EPOCHS}]\")\n",
    "    print(f\"Train | Loss: {train_metrics['train_loss']:.4f} | \"\n",
    "          f\"Acc: {train_metrics['train_acc']:.4f} | \"\n",
    "          f\"F1: {train_metrics['train_f1']:.4f}\")\n",
    "    print(f\"Valid | Loss: {val_metrics['val_loss']:.4f} | \"\n",
    "          f\"Acc: {val_metrics['val_acc']:.4f} | \"\n",
    "          f\"F1: {val_metrics['val_f1']:.4f}\")\n",
    "\n",
    "    # 4ï¸âƒ£ Save Best Model\n",
    "    if val_metrics[\"val_f1\"] > best_f1:\n",
    "        best_f1 = val_metrics[\"val_f1\"]\n",
    "        torch.save({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "            \"val_loss\": val_metrics[\"val_loss\"],\n",
    "            \"val_f1\": val_metrics[\"val_f1\"],\n",
    "        }, f\"./best_model_f1_{best_f1:.4f}_epoch{epoch+1}.pt\")\n",
    "        print(f\"âœ… Best model updated! (F1: {best_f1:.4f})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model weights saved as final_model_convnext_tiny.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ğŸ” Inference:   0%|                                                                                                                     | 0/50 [00:00<?, ?it/s]/tmp/ipykernel_85164/265959225.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "ğŸ” Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:06<00:00,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Inference complete! Saved to pred_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ’¾ ëª¨ë¸ ì €ì¥\n",
    "# ------------------------\n",
    "torch.save(model.state_dict(), \"./final_model_convnext_tiny.pt\")\n",
    "print(\"âœ… Model weights saved as final_model_convnext_tiny.pt\")\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§  Inference\n",
    "# ------------------------\n",
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, _ in tqdm(tst_loader, desc=\"ğŸ” Inference\"):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        with torch.cuda.amp.autocast():\n",
    "            preds = model(images)\n",
    "        preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ“Š ê²°ê³¼ DataFrame ìƒì„±\n",
    "# ------------------------\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=[\"ID\", \"target\"])\n",
    "pred_df[\"target\"] = preds_list\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ” ìƒ˜í”Œ ì œì¶œ íŒŒì¼ê³¼ ìˆœì„œ ê²€ì¦\n",
    "# ------------------------\n",
    "sample_submission_df = pd.read_csv(\"../../../data/raw/sample_submission.csv\")\n",
    "assert (sample_submission_df[\"ID\"] == pred_df[\"ID\"]).all(), \"âš ï¸ ID ìˆœì„œ ë¶ˆì¼ì¹˜!\"\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ’¾ ìµœì¢… CSV ì €ì¥\n",
    "# ------------------------\n",
    "save_path = \"pred_6.csv\"\n",
    "pred_df.to_csv(save_path, index=False)\n",
    "print(f\"ğŸ¯ Inference complete! Saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
