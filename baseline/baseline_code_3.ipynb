{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ”¥ Using GPU: {gpu_name}\")\n",
    "    torch.backends.cudnn.benchmark = True  # ì…ë ¥ í¬ê¸° ê³ ì •ì´ë©´ ë” ë¹ ë¦„\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ GPU not available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import os, random, numpy as np, torch\n",
    "\n",
    "# ------------------------\n",
    "# Reproducibility & GPU Optimization\n",
    "# ------------------------\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# âš™ï¸ cuDNN settings\n",
    "torch.backends.cudnn.deterministic = False  # Trueë©´ ì¬í˜„ì„±â†‘, ì†ë„â†“\n",
    "torch.backends.cudnn.benchmark = True       # ì…ë ¥ í¬ê¸° ê³ ì •ì´ë©´ ì†ë„â†‘\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "# âš¡ Device check\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ”¥ Using GPU: {gpu_name}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ Using CPU. (No CUDA detected)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv_or_df, path, transform=None):\n",
    "        # csv ê²½ë¡œ(str) or DataFrame ëª¨ë‘ í—ˆìš©\n",
    "        if isinstance(csv_or_df, str):\n",
    "            self.df = pd.read_csv(csv_or_df).values\n",
    "        else:\n",
    "            self.df = csv_or_df.values\n",
    "\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert(\"RGB\"))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        return img, target\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler=None):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    preds_list, targets_list = [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
    "\n",
    "    for images, targets in pbar:\n",
    "        images, targets = images.to(device, non_blocking=True), targets.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # âš¡ Mixed Precision Training\n",
    "        with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        # âœ… backward (scaler ìˆì„ ë•Œì™€ ì—†ì„ ë•Œ ëª¨ë‘ ì§€ì›)\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Logging\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    # Epoch metrics\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”¥ Using GPU: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# ------------------------\n",
    "# âš¡ Device setting\n",
    "# ------------------------\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"ğŸ”¥ Using GPU: {gpu_name}\")\n",
    "    torch.backends.cudnn.benchmark = True  # ì…ë ¥ í¬ê¸° ê³ ì •ì´ë©´ ì†ë„ â†‘\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"âš ï¸ Using CPU. (No CUDA detected)\")\n",
    "\n",
    "# ------------------------\n",
    "# âš™ï¸ Data config\n",
    "# ------------------------\n",
    "data_path = \"../../../data/raw/\"\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§  Model config\n",
    "# ------------------------\n",
    "# ë¬¸ì„œ ë¶„ë¥˜ ì •í™•ë„ ìš°ì„  ì„¸íŒ… (ConvNeXt-Tiny)\n",
    "model_name = \"convnext_tiny.fb_in22k_ft_in1k\"  # ImageNet22k â†’ 1k fine-tuned ê°€ì¤‘ì¹˜ ì‚¬ìš©\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ“ˆ Training config (RTX 3090 ìµœì í™”)\n",
    "# ------------------------\n",
    "img_size = 384            # ë¬¸ì„œ ì´ë¯¸ì§€ë©´ 384~512 ì¶”ì²œ\n",
    "LR = 5e-4                 # ConvNeXt-Tinyì—ë„ ì˜ ë§ëŠ” ê°’\n",
    "EPOCHS = 15               # ì•½ê°„ ë” ê¸´ í•™ìŠµ ì¶”ì²œ (10 â†’ 15)\n",
    "BATCH_SIZE = 64           # ConvNeXtëŠ” EfficientNetë³´ë‹¤ ë©”ëª¨ë¦¬ ì¡°ê¸ˆ ë” ì”€\n",
    "num_workers = 8           # CPU ë³‘ë ¬ ì²˜ë¦¬ ê°•í™”\n",
    "pin_memory = True\n",
    "persistent_workers = True\n",
    "prefetch_factor = 4       # DataLoader ì„±ëŠ¥ ê°œì„ \n",
    "\n",
    "# ------------------------\n",
    "# ğŸ’¡ Notes\n",
    "# ------------------------\n",
    "# - ConvNeXt-TinyëŠ” êµ¬ì¡°ì ìœ¼ë¡œ EfficientNetë³´ë‹¤ ê¹Šê³  ë„“ì€ ëª¨ë¸ì´ë¼,\n",
    "#   GPU ì‚¬ìš©ëŸ‰ì€ ì•½ 1.5~2ë°° ë†’ì§€ë§Œ, ë¬¸ì„œ(í…ìŠ¤íŠ¸/ë„ì¥/ë ˆì´ì•„ì›ƒ) ë¶„ë¥˜ ì„±ëŠ¥ì´ í›¨ì”¬ ì¢‹ìŒ.\n",
    "# - AMP ì‚¬ìš© ì‹œ ì†ë„ëŠ” ê±°ì˜ ë™ì¼, ë©”ëª¨ë¦¬ ì ˆì•½ íš¨ê³¼ í¼.\n",
    "# - ëª¨ë¸ ë¡œë“œëŠ” ì•„ë˜ì²˜ëŸ¼ í•˜ë©´ ë¨:\n",
    "#     import timm\n",
    "#     model = timm.create_model(model_name, pretrained=True, num_classes=NUM_CLASSES)\n",
    "#     model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_42617/4228722789.py:15: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(5, 30), p=0.5),\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§© Train Transform\n",
    "# ------------------------\n",
    "trn_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),        # í•´ìƒë„ í†µì¼\n",
    "    A.HorizontalFlip(p=0.5),                          # ë¬¸ì„œ ì¢Œìš° ë’¤ì§‘ê¸° í—ˆìš©\n",
    "    A.ShiftScaleRotate(\n",
    "        shift_limit=0.02, scale_limit=0.05, rotate_limit=3, p=0.3\n",
    "    ),                                                # ë¬¸ì„œ ê¸°ìš¸ê¸° ì•½ê°„ë§Œ í—ˆìš©\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=3, p=0.5),\n",
    "        A.GaussNoise(var_limit=(5, 30), p=0.5),\n",
    "    ], p=0.2),                                        # ìŠ¤ìº” ë…¸ì´ì¦ˆÂ·íë¦¼ ì•½í•˜ê²Œ\n",
    "    A.RandomBrightnessContrast(\n",
    "        brightness_limit=0.1, contrast_limit=0.1, p=0.2\n",
    "    ),\n",
    "    A.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§© Validation / Test Transform\n",
    "# ------------------------\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(\n",
    "        mean=(0.485, 0.456, 0.406),\n",
    "        std=(0.229, 0.224, 0.225)\n",
    "    ),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "INxdmsStop2L",
    "outputId": "49f0d412-8ce6-4d2f-ae78-d5cf3d056340"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 1ï¸âƒ£ train.csv ë¡œë“œ\n",
    "full_df = pd.read_csv(\"../../../data/raw/train.csv\")\n",
    "\n",
    "# 2ï¸âƒ£ train/val ë¶„ë¦¬ (stratifyë¡œ í´ë˜ìŠ¤ ê· í˜• ìœ ì§€)\n",
    "trn_df, val_df = train_test_split(\n",
    "    full_df, test_size=0.2, stratify=full_df['target'], random_state=42\n",
    ")\n",
    "\n",
    "# 3ï¸âƒ£ Dataset ì •ì˜\n",
    "trn_dataset = ImageDataset(trn_df, \"../../../data/raw/train/\", transform=trn_transform)\n",
    "val_dataset = ImageDataset(val_df, \"../../../data/raw/train/\", transform=tst_transform)\n",
    "tst_dataset = ImageDataset(\"../../../data/raw/sample_submission.csv\",\n",
    "                           \"../../../data/raw/test/\", transform=tst_transform)\n",
    "\n",
    "# 4ï¸âƒ£ Loader ì •ì˜\n",
    "trn_loader = DataLoader(trn_dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        num_workers=num_workers, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=num_workers, pin_memory=True)\n",
    "tst_loader = DataLoader(tst_dataset, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        num_workers=num_workers, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112808,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "_sO03fWaQj1h"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Train loader\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "# Validation loader\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor\n",
    ")\n",
    "\n",
    "# Test loader (inference ì „ìš©)\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory,\n",
    "    persistent_workers=persistent_workers,\n",
    "    prefetch_factor=prefetch_factor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42617/997026691.py:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ§  Load Model\n",
    "# ------------------------\n",
    "model = timm.create_model(\n",
    "    model_name,                 # \"convnext_tiny.fb_in22k_ft_in1k\"\n",
    "    pretrained=True,\n",
    "    num_classes=17,             # ë¬¸ì„œ í´ë˜ìŠ¤ ê°œìˆ˜\n",
    "    in_chans=3,\n",
    "    drop_path_rate=0.1          # stochastic depth ì‚´ì§ ì¶”ê°€ (ì¼ë°˜í™”â†‘)\n",
    ").to(device)\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ’¥ Loss Function\n",
    "# ------------------------\n",
    "# ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ì—ì„œëŠ” ì•½ê°„ì˜ label noise ê°€ëŠ¥ì„± ìˆìœ¼ë¯€ë¡œ Label Smoothing ì¶”ì²œ\n",
    "loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "# ------------------------\n",
    "# âš™ï¸ Optimizer\n",
    "# ------------------------\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LR,                      # 5e-4\n",
    "    weight_decay=1e-4            # ì¼ë°˜ì  weight decay (1e-2 â†’ 1e-4ë¡œ ì•ˆì •í™”)\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# ğŸ“ˆ Scheduler\n",
    "# ------------------------\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=EPOCHS,\n",
    "    eta_min=1e-5                # í›„ë°˜ í•™ìŠµ ì•ˆì •í™”\n",
    ")\n",
    "\n",
    "# ------------------------\n",
    "# âš¡ AMP Scaler\n",
    "# ------------------------\n",
    "scaler = torch.cuda.amp.GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 1/15]\n",
      "Train | Loss: 2.1260 | Acc: 0.4013 | F1: 0.3604\n",
      "Valid | Loss: 1.2944 | Acc: 0.6592 | F1: 0.5639\n",
      "âœ… Best model saved! (F1: 0.5639)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 2/15]\n",
      "Train | Loss: 1.2254 | Acc: 0.7434 | F1: 0.7181\n",
      "Valid | Loss: 0.9446 | Acc: 0.8599 | F1: 0.8140\n",
      "âœ… Best model saved! (F1: 0.8140)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 3/15]\n",
      "Train | Loss: 0.9773 | Acc: 0.8331 | F1: 0.8100\n",
      "Valid | Loss: 0.8284 | Acc: 0.9172 | F1: 0.9114\n",
      "âœ… Best model saved! (F1: 0.9114)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 4/15]\n",
      "Train | Loss: 0.8884 | Acc: 0.8824 | F1: 0.8614\n",
      "Valid | Loss: 0.8123 | Acc: 0.8917 | F1: 0.8772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 5/15]\n",
      "Train | Loss: 0.8194 | Acc: 0.9071 | F1: 0.8920\n",
      "Valid | Loss: 0.7648 | Acc: 0.9268 | F1: 0.9256\n",
      "âœ… Best model saved! (F1: 0.9256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 6/15]\n",
      "Train | Loss: 0.7694 | Acc: 0.9243 | F1: 0.9155\n",
      "Valid | Loss: 0.7117 | Acc: 0.9331 | F1: 0.9271\n",
      "âœ… Best model saved! (F1: 0.9271)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 7/15]\n",
      "Train | Loss: 0.7286 | Acc: 0.9400 | F1: 0.9360\n",
      "Valid | Loss: 0.6937 | Acc: 0.9490 | F1: 0.9443\n",
      "âœ… Best model saved! (F1: 0.9443)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 8/15]\n",
      "Train | Loss: 0.6914 | Acc: 0.9572 | F1: 0.9521\n",
      "Valid | Loss: 0.6992 | Acc: 0.9618 | F1: 0.9601\n",
      "âœ… Best model saved! (F1: 0.9601)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 9/15]\n",
      "Train | Loss: 0.6739 | Acc: 0.9696 | F1: 0.9687\n",
      "Valid | Loss: 0.6839 | Acc: 0.9618 | F1: 0.9595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 10/15]\n",
      "Train | Loss: 0.6623 | Acc: 0.9646 | F1: 0.9622\n",
      "Valid | Loss: 0.6790 | Acc: 0.9650 | F1: 0.9633\n",
      "âœ… Best model saved! (F1: 0.9633)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 11/15]\n",
      "Train | Loss: 0.6462 | Acc: 0.9794 | F1: 0.9795\n",
      "Valid | Loss: 0.6764 | Acc: 0.9777 | F1: 0.9762\n",
      "âœ… Best model saved! (F1: 0.9762)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 12/15]\n",
      "Train | Loss: 0.6243 | Acc: 0.9926 | F1: 0.9923\n",
      "Valid | Loss: 0.6678 | Acc: 0.9809 | F1: 0.9791\n",
      "âœ… Best model saved! (F1: 0.9791)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 13/15]\n",
      "Train | Loss: 0.6275 | Acc: 0.9885 | F1: 0.9882\n",
      "Valid | Loss: 0.6684 | Acc: 0.9809 | F1: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 14/15]\n",
      "Train | Loss: 0.6134 | Acc: 0.9918 | F1: 0.9916\n",
      "Valid | Loss: 0.6650 | Acc: 0.9809 | F1: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                                                         | 0/19 [00:00<?, ?it/s]/tmp/ipykernel_42617/459546472.py:18: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=(scaler is not None)):\n",
      "                                                                                                                                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Epoch 15/15]\n",
      "Train | Loss: 0.6113 | Acc: 0.9926 | F1: 0.9919\n",
      "Valid | Loss: 0.6649 | Acc: 0.9809 | F1: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "\n",
    "# ------------------------\n",
    "# âš™ï¸ Validation í•¨ìˆ˜ ì •ì˜\n",
    "# ------------------------\n",
    "@torch.no_grad()\n",
    "def validate(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss, preds_list, targets_list = 0.0, [], []\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Validating\", leave=False)\n",
    "    for images, targets in pbar:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            preds = model(images)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        val_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# ğŸš€ Training Loop\n",
    "# ------------------------\n",
    "best_f1 = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # 1ï¸âƒ£ Train for one epoch\n",
    "    train_metrics = train_one_epoch(trn_loader, model, optimizer, loss_fn, device, scaler)\n",
    "\n",
    "    # 2ï¸âƒ£ Validation\n",
    "    val_metrics = validate(val_loader, model, loss_fn, device)\n",
    "\n",
    "    # 3ï¸âƒ£ Scheduler step\n",
    "    scheduler.step()\n",
    "\n",
    "    # 4ï¸âƒ£ Logging\n",
    "    print(f\"\\n[Epoch {epoch+1}/{EPOCHS}]\")\n",
    "    print(f\"Train | Loss: {train_metrics['train_loss']:.4f} | \"\n",
    "          f\"Acc: {train_metrics['train_acc']:.4f} | \"\n",
    "          f\"F1: {train_metrics['train_f1']:.4f}\")\n",
    "    print(f\"Valid | Loss: {val_metrics['val_loss']:.4f} | \"\n",
    "          f\"Acc: {val_metrics['val_acc']:.4f} | \"\n",
    "          f\"F1: {val_metrics['val_f1']:.4f}\")\n",
    "\n",
    "    # 5ï¸âƒ£ Save best model\n",
    "    if val_metrics[\"val_f1\"] > best_f1:\n",
    "        best_f1 = val_metrics[\"val_f1\"]\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"scheduler_state_dict\": scheduler.state_dict(),\n",
    "                \"val_loss\": val_metrics[\"val_loss\"],\n",
    "                \"val_f1\": val_metrics[\"val_f1\"],\n",
    "            },\n",
    "            f\"./best_model_f1_{best_f1:.4f}_epoch{epoch+1}.pt\"\n",
    "        )\n",
    "        print(f\"âœ… Best model saved! (F1: {best_f1:.4f})\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model weights saved as final_model_convnext_tiny.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:12<00:00,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Inference complete! Saved to pred_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# âœ… ëª¨ë¸ ì €ì¥ (í›ˆë ¨ ì™„ë£Œ í›„, ì¶”ë¡  ì „ì—)\n",
    "torch.save(model.state_dict(), \"./final_model_convnext_tiny.pt\")\n",
    "print(\"âœ… Model weights saved as final_model_convnext_tiny.pt\")\n",
    "\n",
    "# âœ… ì¶”ë¡  (Inference)\n",
    "preds_list = []\n",
    "\n",
    "model.eval()\n",
    "for image, _ in tqdm(tst_loader, desc=\"Inference\"):\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(image)\n",
    "\n",
    "    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "\n",
    "# âœ… ê²°ê³¼ DataFrame ìƒì„±\n",
    "pred_df = pd.DataFrame(tst_dataset.df, columns=[\"ID\", \"target\"])\n",
    "pred_df[\"target\"] = preds_list\n",
    "\n",
    "# âœ… ìƒ˜í”Œ ì œì¶œ íŒŒì¼ê³¼ ì •ë ¬ ê²€ì¦\n",
    "sample_submission_df = pd.read_csv(\"../../../data/raw/sample_submission.csv\")\n",
    "assert (sample_submission_df[\"ID\"] == pred_df[\"ID\"]).all(), \"âš ï¸ ID ìˆœì„œ ë¶ˆì¼ì¹˜!\"\n",
    "\n",
    "# âœ… ìµœì¢… ì œì¶œ íŒŒì¼ ì €ì¥\n",
    "pred_df.to_csv(\"pred_3.csv\", index=False)\n",
    "print(\"ğŸ¯ Inference complete! Saved to pred_2.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
