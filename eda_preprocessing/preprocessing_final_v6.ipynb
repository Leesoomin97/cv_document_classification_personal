{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd8bfac0-4e24-4c29-9506-11466cefac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded meta_grouped.csv for TRAIN: (1570, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1570/1570 [00:23<00:00, 65.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì™„ë£Œ (TRAIN): ì €ì¥ 1570ì¥, ì‹¤íŒ¨ 0ì¥ â†’ /data/ephemeral/home/data/processed/stage0_6_train_v6\n",
      "âœ… TEST í´ë”ì—ì„œ ì§ì ‘ íŒŒì¼ íƒìƒ‰ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3140/3140 [00:45<00:00, 69.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ì™„ë£Œ (TEST): ì €ì¥ 3140ì¥, ì‹¤íŒ¨ 0ì¥ â†’ /data/ephemeral/home/data/processed/stage0_6_test_v6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import traceback\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "\n",
    "# ============================================================\n",
    "# ğŸŒŸ Core Utils\n",
    "# ============================================================\n",
    "\n",
    "def resize_with_padding(img, target=1024, pad_color=(255, 255, 255)):\n",
    "    \"\"\"ë¦¬ì‚¬ì´ì¦ˆ í›„ í°ìƒ‰ íŒ¨ë”©ìœ¼ë¡œ ì •ì‚¬ê° ì •ê·œí™”\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    s = target / max(h, w)\n",
    "    nh, nw = int(h * s), int(w * s)\n",
    "    img = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA if s < 1 else cv2.INTER_CUBIC)\n",
    "    top = (target - nh) // 2\n",
    "    bottom = target - nh - top\n",
    "    left = (target - nw) // 2\n",
    "    right = target - nw - left\n",
    "    return cv2.copyMakeBorder(img, top, bottom, left, right, cv2.BORDER_CONSTANT, value=pad_color)\n",
    "\n",
    "def lap_var(img_gray):\n",
    "    return cv2.Laplacian(img_gray, cv2.CV_64F).var()\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ“ Crop / Padding ë³´ì •\n",
    "# ============================================================\n",
    "\n",
    "def detect_crop_need(img, edge_thresh=0.07, bright_thresh=0.2):\n",
    "    \"\"\"ë¬¸ì„œê°€ ì˜ë ¸ëŠ”ì§€ ê°ì§€\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    h, w = gray.shape\n",
    "    border_w, border_h = int(w * 0.05), int(h * 0.05)\n",
    "\n",
    "    edge = cv2.Sobel(gray, cv2.CV_32F, 1, 1, ksize=3)\n",
    "    edge = np.abs(edge) / 255.0\n",
    "\n",
    "    outer = edge[:border_h, :].mean() + edge[-border_h:, :].mean() \\\n",
    "           + edge[:, :border_w].mean() + edge[:, -border_w:].mean()\n",
    "    inner = edge[border_h:-border_h, border_w:-border_w].mean()\n",
    "\n",
    "    bright_outer = gray[:border_h, :].mean() + gray[-border_h:, :].mean() \\\n",
    "                  + gray[:, :border_w].mean() + gray[:, -border_w:].mean()\n",
    "    bright_inner = gray[border_h:-border_h, border_w:-border_w].mean()\n",
    "\n",
    "    edge_gap = max(outer - inner, 0)\n",
    "    bright_gap = abs(bright_outer - bright_inner) / 255.0\n",
    "\n",
    "    return (edge_gap > edge_thresh) or (bright_gap > bright_thresh)\n",
    "\n",
    "def safe_constant_padding(img, pad_ratio=0.1, pad_color=(255,255,255)):\n",
    "    \"\"\"ì¡°ê±´ë¶€ í°ìƒ‰ íŒ¨ë”©\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "    ph, pw = int(h * pad_ratio), int(w * pad_ratio)\n",
    "    return cv2.copyMakeBorder(img, ph, ph, pw, pw, cv2.BORDER_CONSTANT, value=pad_color)\n",
    "\n",
    "# ============================================================\n",
    "# â˜€ï¸ Illumination & Color\n",
    "# ============================================================\n",
    "\n",
    "def grayworld_white_balance_soft(img):\n",
    "    \"\"\"ì»¬ëŸ¬ ê· í˜• ì™„í™” ë²„ì „ (ViT/OCR-friendly)\"\"\"\n",
    "    b, g, r = cv2.split(img.astype(np.float32))\n",
    "    mean = (b.mean() + g.mean() + r.mean()) / 3.0 + 1e-6\n",
    "    for ch in [b, g, r]:\n",
    "        ch *= (mean / (ch.mean() + 1e-6))\n",
    "    merged = cv2.merge([b, g, r])\n",
    "    return np.clip(merged, 0, 255).astype(np.uint8)\n",
    "\n",
    "def lab_equalize_L_contrast(img, clip=1.3, tile=10):\n",
    "    \"\"\"LAB ê¸°ë°˜ ëŒ€ë¹„ ê°•í™” (OCR-friendly CLAHE)\"\"\"\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip, tileGridSize=(tile, tile))\n",
    "    l2 = clahe.apply(l)\n",
    "    lab = cv2.merge([l2, a, b])\n",
    "    return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def apply_gamma_auto(img, base=1.05, max_gamma=1.08):\n",
    "    \"\"\"ë°ê¸° ê¸°ë°˜ ìë™ ê°ë§ˆ ë³´ì •\"\"\"\n",
    "    mean = np.mean(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)) / 255.0\n",
    "    gamma = np.clip(base + (0.5 - mean) * 0.4, 0.9, max_gamma)\n",
    "    inv = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** inv * 255 for i in np.arange(256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(img, table)\n",
    "\n",
    "def adaptive_unsharp(img, base_sigma=1.0, base_strength=0.22):\n",
    "    \"\"\"ì•½í•œ ì–¸ìƒµ (OCR-friendly sharpness)\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    lv = lap_var(gray)\n",
    "    blur_score = np.clip((500.0 - min(lv, 500.0)) / 500.0, 0, 1)\n",
    "    strength = base_strength * (0.4 + 0.6 * blur_score)\n",
    "    sigma = base_sigma * (0.8 + 0.7 * blur_score)\n",
    "    blur = cv2.GaussianBlur(img, (0, 0), sigma)\n",
    "    sharp = cv2.addWeighted(img, 1 + strength, blur, -strength, 0)\n",
    "    return np.clip(sharp, 0, 255).astype(np.uint8)\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ§© ì „ì²´ íŒŒì´í”„ë¼ì¸ (Ensemble + OCR)\n",
    "# ============================================================\n",
    "\n",
    "def preprocess_image(img, target=1024):\n",
    "    # 1ï¸âƒ£ ì˜ë¦¼ ê°ì§€ í›„ ì¡°ê±´ë¶€ íŒ¨ë”©\n",
    "    if detect_crop_need(img):\n",
    "        img = safe_constant_padding(img, pad_ratio=0.08)\n",
    "\n",
    "    # 2ï¸âƒ£ ìƒ‰ìƒ í‰íƒ„í™” (ViT/OCR ì•ˆì •)\n",
    "    img = grayworld_white_balance_soft(img)\n",
    "\n",
    "    # 3ï¸âƒ£ LAB ëŒ€ë¹„ ê°•í™” (OCR-friendly)\n",
    "    img = lab_equalize_L_contrast(img, clip=1.3, tile=10)\n",
    "\n",
    "    # 4ï¸âƒ£ ê°ë§ˆ ë³´ì • ìë™í™”\n",
    "    img = apply_gamma_auto(img, base=1.05, max_gamma=1.08)\n",
    "\n",
    "    # 5ï¸âƒ£ ì•½í•œ ì–¸ìƒµ (ì—£ì§€ ë³µì›)\n",
    "    img = adaptive_unsharp(img, base_sigma=1.0, base_strength=0.22)\n",
    "\n",
    "    # 6ï¸âƒ£ ì •ê·œ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    img = resize_with_padding(img, target, pad_color=(255,255,255))\n",
    "    return img\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ§¾ ì‹¤í–‰ í•¨ìˆ˜ë“¤ (train/test ë™ì¼)\n",
    "# ============================================================\n",
    "\n",
    "def run_preprocess(RAW_DIR, SAVE_DIR, META_CSV, OUTPUT_META_PATH, mode):\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    meta = pd.read_csv(META_CSV)\n",
    "    meta = meta[meta[\"group\"].notna()]\n",
    "    print(f\"âœ… Loaded meta_grouped.csv for {mode.upper()}: {meta.shape}\")\n",
    "\n",
    "    meta[\"basename\"] = meta[\"filepath\"].apply(lambda x: os.path.basename(x).split(\"_\", 1)[-1])\n",
    "    all_files = glob.glob(os.path.join(RAW_DIR, \"**\", \"*.*\"), recursive=True)\n",
    "    all_basenames = {os.path.basename(f) for f in all_files}\n",
    "    meta = meta[meta[\"basename\"].isin(all_basenames)].reset_index(drop=True)\n",
    "\n",
    "    ok, fail = 0, 0\n",
    "    paths, groups, basenames = [], [], []\n",
    "\n",
    "    for _, row in tqdm(meta.iterrows(), total=len(meta)):\n",
    "        base = row[\"basename\"]\n",
    "        g = row[\"group\"]\n",
    "        matches = glob.glob(os.path.join(RAW_DIR, \"**\", base), recursive=True)\n",
    "        if not matches:\n",
    "            fail += 1\n",
    "            continue\n",
    "        img = cv2.imread(matches[0])\n",
    "        if img is None:\n",
    "            fail += 1\n",
    "            continue\n",
    "        try:\n",
    "            out = preprocess_image(img, target=1024)\n",
    "            save_dir_group = os.path.join(SAVE_DIR, g)\n",
    "            os.makedirs(save_dir_group, exist_ok=True)\n",
    "            save_path = os.path.join(save_dir_group, base)\n",
    "            cv2.imwrite(save_path, out)\n",
    "            paths.append(save_path)\n",
    "            groups.append(g)\n",
    "            basenames.append(base)\n",
    "            ok += 1\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            fail += 1\n",
    "\n",
    "    pd.DataFrame({\"filepath\": paths, \"group\": groups, \"basename\": basenames}).to_csv(OUTPUT_META_PATH, index=False)\n",
    "    print(f\"ğŸ¯ ì™„ë£Œ ({mode.upper()}): ì €ì¥ {ok}ì¥, ì‹¤íŒ¨ {fail}ì¥ â†’ {SAVE_DIR}\")\n",
    "\n",
    "def run_preprocess_test(RAW_DIR, SAVE_DIR, OUTPUT_META_PATH):\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "    print(f\"âœ… TEST í´ë”ì—ì„œ ì§ì ‘ íŒŒì¼ íƒìƒ‰ ì¤‘...\")\n",
    "    all_files = glob.glob(os.path.join(RAW_DIR, \"**\", \"*.*\"), recursive=True)\n",
    "    all_files = [f for f in all_files if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "\n",
    "    ok, fail = 0, 0\n",
    "    paths, basenames = [], []\n",
    "\n",
    "    for fp in tqdm(all_files):\n",
    "        base = os.path.basename(fp)\n",
    "        img = cv2.imread(fp)\n",
    "        if img is None:\n",
    "            fail += 1\n",
    "            continue\n",
    "        try:\n",
    "            out = preprocess_image(img, target=1024)\n",
    "            save_path = os.path.join(SAVE_DIR, base)\n",
    "            cv2.imwrite(save_path, out)\n",
    "            paths.append(save_path)\n",
    "            basenames.append(base)\n",
    "            ok += 1\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "            fail += 1\n",
    "\n",
    "    pd.DataFrame({\"filepath\": paths, \"basename\": basenames}).to_csv(OUTPUT_META_PATH, index=False)\n",
    "    print(f\"ğŸ¯ ì™„ë£Œ (TEST): ì €ì¥ {ok}ì¥, ì‹¤íŒ¨ {fail}ì¥ â†’ {SAVE_DIR}\")\n",
    "\n",
    "# ============================================================\n",
    "# ğŸ§  MAIN\n",
    "# ============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    BASE = \"/data/ephemeral/home/data\"\n",
    "    META = f\"{BASE}/interim/meta_grouped.csv\"\n",
    "\n",
    "    run_preprocess(\n",
    "        RAW_DIR=f\"{BASE}/raw/train\",\n",
    "        SAVE_DIR=f\"{BASE}/processed/stage0_6_train_v6\",\n",
    "        META_CSV=META,\n",
    "        OUTPUT_META_PATH=f\"{BASE}/meta_stage0_6_train_v6.csv\",\n",
    "        mode=\"train\"\n",
    "    )\n",
    "\n",
    "    run_preprocess_test(\n",
    "        RAW_DIR=f\"{BASE}/raw/test\",\n",
    "        SAVE_DIR=f\"{BASE}/processed/stage0_6_test_v6\",\n",
    "        OUTPUT_META_PATH=f\"{BASE}/meta_stage0_6_test_v6.csv\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624072c-c384-4148-bccf-7d2e3bc7b0d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
