{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeaaf04e-9a33-4d19-8981-8298ad1a2a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Total: 14130 | Train: 11304 | Holdout: 2826\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# v9_holdout_ensemble_b3_vit_convnext.py\n",
    "# ------------------------------------------------------------\n",
    "# ‚úÖ Train / Holdout = v9 (root-level stratified 8:2)\n",
    "# ‚úÖ Models: EfficientNet-B3, ConvNeXt-Small, ViT-B16\n",
    "# ‚úÖ 4-way TTA (orig, hflip, rotate ¬±7¬∞)\n",
    "# ‚úÖ Auto-weight ensemble (no floor)\n",
    "# ============================================================\n",
    "\n",
    "import os, gc, math, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import timm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Config\n",
    "# ============================================================\n",
    "BASE = \"/data/ephemeral/home/data\"\n",
    "\n",
    "META_V9 = f\"{BASE}/meta_stage0_9_train_v9.csv\"\n",
    "TRAIN_CSV = f\"{BASE}/raw/train.csv\"\n",
    "SUB_CSV = f\"{BASE}/raw/sample_submission.csv\"\n",
    "TRAIN_IMG_V9 = f\"{BASE}/processed/stage0_9_train_v9\"\n",
    "TEST_IMG_V8 = f\"{BASE}/processed/stage0_8_test_v8\"\n",
    "\n",
    "OUT_DIR = \"./runs_v9_holdout\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(f\"{OUT_DIR}/models\", exist_ok=True)\n",
    "os.makedirs(f\"{OUT_DIR}/test_probs\", exist_ok=True)\n",
    "os.makedirs(f\"{OUT_DIR}/debug\", exist_ok=True)\n",
    "\n",
    "CFG = dict(\n",
    "    seed=42, num_classes=17,\n",
    "    img_size_b3=380, img_size_conv=384, img_size_vit=384,\n",
    "    batch_size=16, epochs=50, early_stop=8,\n",
    "    lr=1e-4, wd=1e-4, label_smooth=0.05,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Utils\n",
    "# ============================================================\n",
    "def set_seed(seed):\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def row_normalize(x):\n",
    "    x = np.clip(np.asarray(x, dtype=np.float64), 1e-12, None)\n",
    "    return (x / x.sum(1, keepdims=True)).astype(np.float32)\n",
    "\n",
    "def corrcoef(a, b):\n",
    "    a = a - a.mean(axis=1, keepdims=True)\n",
    "    b = b - b.mean(axis=1, keepdims=True)\n",
    "    return float(np.mean(((a / np.linalg.norm(a, axis=1, keepdims=True)) *\n",
    "                          (b / np.linalg.norm(b, axis=1, keepdims=True))).sum(1)))\n",
    "\n",
    "def temp_scale(probs, T):\n",
    "    logits = np.log(np.clip(probs, 1e-12, 1.0)) / T\n",
    "    e = np.exp(logits - logits.max(1, keepdims=True))\n",
    "    return row_normalize(e)\n",
    "\n",
    "def fit_temperature(probs, targets, t_min=0.8, t_max=2.0, steps=25):\n",
    "    ys = np.eye(CFG[\"num_classes\"])[targets]\n",
    "    best_T, best_nll = 1.0, 1e9\n",
    "    for T in np.linspace(t_min, t_max, steps):\n",
    "        p = temp_scale(probs, T)\n",
    "        nll = -np.sum(ys * np.log(np.clip(p, 1e-12, 1.0))) / len(targets)\n",
    "        if nll < best_nll:\n",
    "            best_nll, best_T = nll, T\n",
    "    return best_T\n",
    "\n",
    "def save_npz(path, arr):\n",
    "    np.savez_compressed(path, np.asarray(arr, dtype=np.float32))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Data prep (root-level split)\n",
    "# ============================================================\n",
    "set_seed(CFG[\"seed\"])\n",
    "\n",
    "meta = pd.read_csv(META_V9)\n",
    "train_raw = pd.read_csv(TRAIN_CSV)\n",
    "\n",
    "train_raw[\"ID_norm\"] = train_raw[\"ID\"].apply(lambda x: x if x.endswith(\".jpg\") else f\"{x}.jpg\")\n",
    "id2tgt = dict(zip(train_raw[\"ID_norm\"], train_raw[\"target\"]))\n",
    "\n",
    "meta[\"root_id\"] = meta[\"basename\"].apply(lambda x: os.path.splitext(x)[0].split(\"_aug\")[0] + \".jpg\")\n",
    "meta[\"target\"] = meta[\"root_id\"].map(id2tgt)\n",
    "meta = meta.dropna(subset=[\"target\"]).reset_index(drop=True)\n",
    "meta[\"target\"] = meta[\"target\"].astype(int)\n",
    "\n",
    "meta[\"filepath\"] = meta.apply(\n",
    "    lambda r: os.path.join(TRAIN_IMG_V9, str(r[\"group\"]), str(r[\"basename\"])), axis=1\n",
    ")\n",
    "\n",
    "orig = meta[~meta[\"basename\"].str.contains(\"_aug\")][[\"root_id\", \"target\"]].drop_duplicates()\n",
    "train_roots, hold_roots = train_test_split(\n",
    "    orig[\"root_id\"], test_size=0.2, random_state=CFG[\"seed\"], stratify=orig[\"target\"]\n",
    ")\n",
    "\n",
    "train_df = meta[meta[\"root_id\"].isin(train_roots)].reset_index(drop=True)\n",
    "hold_df = meta[meta[\"root_id\"].isin(hold_roots)].reset_index(drop=True)\n",
    "\n",
    "print(f\"‚úÖ Total: {len(meta)} | Train: {len(train_df)} | Holdout: {len(hold_df)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb332fb-70ca-4fb4-865a-bfe52d0d780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Transforms\n",
    "# ============================================================\n",
    "def build_transforms(img_size, is_train=True):\n",
    "    if is_train:\n",
    "        return A.Compose([\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.ShiftScaleRotate(shift_limit=0.03, scale_limit=0.05,\n",
    "                               rotate_limit=7, border_mode=cv2.BORDER_REFLECT_101, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.RandomBrightnessContrast(0.1, 0.1, p=0.3),\n",
    "            A.GaussianBlur(blur_limit=(3, 5), p=0.2),\n",
    "            A.ImageCompression(quality_lower=90, quality_upper=100, p=0.2),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.Resize(img_size, img_size),\n",
    "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Dataset\n",
    "# ============================================================\n",
    "class ImgDataset(Dataset):\n",
    "    def __init__(self, df, img_size, is_train):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.tf = build_transforms(img_size, is_train)\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row[\"filepath\"])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        aug = self.tf(image=img)[\"image\"]\n",
    "        return aug, int(row[\"target\"])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Model Factory\n",
    "# ============================================================\n",
    "def create_model(name, num_classes, drop_rate=0.0, drop_path=0.0):\n",
    "    model = timm.create_model(name, pretrained=True,\n",
    "                              num_classes=num_classes,\n",
    "                              drop_rate=drop_rate, drop_path_rate=drop_path)\n",
    "    model.to(CFG[\"device\"])\n",
    "    model.to(memory_format=torch.channels_last)\n",
    "    if hasattr(model, \"set_grad_checkpointing\"):\n",
    "        model.set_grad_checkpointing(True)\n",
    "    return model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Training Loop\n",
    "# ============================================================\n",
    "def train_one_epoch(model, loader, optimizer, loss_fn, scaler):\n",
    "    model.train(); total = 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(CFG[\"device\"]), yb.to(CFG[\"device\"])\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.autocast(\"cuda\", torch.float16):\n",
    "            out = model(xb); loss = loss_fn(out, yb)\n",
    "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "        total += loss.item()\n",
    "    return total / len(loader)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, loader, loss_fn):\n",
    "    model.eval(); total, probs, tgts = 0, [], []\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(CFG[\"device\"]), yb.to(CFG[\"device\"])\n",
    "        with torch.autocast(\"cuda\", torch.float16):\n",
    "            out = model(xb); loss = loss_fn(out, yb)\n",
    "            p = torch.softmax(out, dim=1).cpu().numpy()\n",
    "        total += loss.item(); probs.append(p); tgts.append(yb.cpu().numpy())\n",
    "    probs = row_normalize(np.vstack(probs)); tgts = np.concatenate(tgts)\n",
    "    f1 = f1_score(tgts, probs.argmax(1), average=\"macro\")\n",
    "    return total / len(loader), f1, probs, tgts\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Backbone trainer\n",
    "# ============================================================\n",
    "def train_backbone(key, train_df, hold_df):\n",
    "    cfg = {\n",
    "        \"b3\":  (\"tf_efficientnet_b3_ns\", CFG[\"img_size_b3\"], 0.4, 0.2),\n",
    "        \"conv\":(\"convnext_small\", CFG[\"img_size_conv\"], 0.0, 0.2),\n",
    "        \"vit\": (\"vit_base_patch16_384\", CFG[\"img_size_vit\"], 0.2, 0.1)\n",
    "    }[key]\n",
    "\n",
    "    name, img_size, dr, dp = cfg\n",
    "    model = create_model(name, CFG[\"num_classes\"], dr, dp)\n",
    "    tr_ld = DataLoader(ImgDataset(train_df, img_size, True), batch_size=CFG[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "    ho_ld = DataLoader(ImgDataset(hold_df, img_size, False), batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=4)\n",
    "    opt = AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"wd\"])\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smooth\"])\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    best, es = -1, 0\n",
    "    for ep in range(1, CFG[\"epochs\"] + 1):\n",
    "        tr_loss = train_one_epoch(model, tr_ld, opt, loss_fn, scaler)\n",
    "        va_loss, va_f1, probs, tgts = validate(model, ho_ld, loss_fn)\n",
    "        print(f\"[{key}] Ep{ep:02d}/{CFG['epochs']} | Tr={tr_loss:.4f} Va={va_loss:.4f} F1={va_f1:.4f}\")\n",
    "        if va_f1 > best:\n",
    "            best, es = va_f1, 0\n",
    "            torch.save(model.state_dict(), f\"{OUT_DIR}/models/{key}_best.pt\")\n",
    "            best_probs, best_tgts = probs, tgts\n",
    "        else: es += 1\n",
    "        if es >= CFG[\"early_stop\"]: break\n",
    "\n",
    "    print(f\"‚úÖ {key} best F1={best:.4f}\")\n",
    "    del model; torch.cuda.empty_cache(); gc.collect()\n",
    "    return best_probs, best_tgts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d223a2-f20a-45f2-bc7b-1c9809cdfaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# TTA inference (4-way)\n",
    "# ============================================================\n",
    "def rotate(img, angle):\n",
    "    if angle == 0: return img\n",
    "    M = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), angle, 1)\n",
    "    return cv2.warpAffine(img, M, (img.shape[1], img.shape[0]), borderMode=cv2.BORDER_REFLECT_101)\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_tta(key, model_path, paths):\n",
    "    name, img_size = {\n",
    "        \"b3\":(\"tf_efficientnet_b3_ns\", CFG[\"img_size_b3\"]),\n",
    "        \"conv\":(\"convnext_small\", CFG[\"img_size_conv\"]),\n",
    "        \"vit\":(\"vit_base_patch16_384\", CFG[\"img_size_vit\"])\n",
    "    }[key]\n",
    "    model = create_model(name, CFG[\"num_classes\"])\n",
    "    model.load_state_dict(torch.load(model_path, map_location=\"cpu\"), strict=True)\n",
    "    model.eval()\n",
    "\n",
    "    tf = build_transforms(img_size, False)\n",
    "    ttas = [(0, False), (0, True), (7, False), (-7, False)]\n",
    "    preds = None\n",
    "\n",
    "    for ang, flip in ttas:\n",
    "        batch, out = [], []\n",
    "        for p in paths:\n",
    "            img = cv2.cvtColor(cv2.imread(p), cv2.COLOR_BGR2RGB)\n",
    "            img = rotate(img, ang)\n",
    "            if flip: img = cv2.flip(img, 1)\n",
    "            batch.append(tf(image=img)[\"image\"])\n",
    "        ds = torch.stack(batch)\n",
    "        dl = DataLoader(ds, batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=2)\n",
    "        for xb in dl:\n",
    "            xb = xb.to(CFG[\"device\"])\n",
    "            with torch.autocast(\"cuda\", torch.float16):\n",
    "                pr = torch.softmax(model(xb), dim=1).cpu().numpy()\n",
    "            out.append(pr)\n",
    "        out = row_normalize(np.vstack(out))\n",
    "        preds = out if preds is None else preds + out\n",
    "\n",
    "    preds /= len(ttas)\n",
    "    del model; torch.cuda.empty_cache(); gc.collect()\n",
    "    return row_normalize(preds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b3189ba-0af9-4b98-8097-8cd9dfc05401",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Ensemble Weight Search\n",
    "# ============================================================\n",
    "def search_weights(p1, p2, p3, y, step=0.05):\n",
    "    best_f1, best_w = -1, (0.33, 0.33, 0.34)\n",
    "    for w1 in np.arange(0, 1.01, step):\n",
    "        for w2 in np.arange(0, 1.01 - w1, step):\n",
    "            w3 = 1 - w1 - w2\n",
    "            mix = row_normalize(w1*p1 + w2*p2 + w3*p3)\n",
    "            f1 = f1_score(y, mix.argmax(1), average=\"macro\")\n",
    "            if f1 > best_f1:\n",
    "                best_f1, best_w = f1, (w1, w2, w3)\n",
    "    return best_w, best_f1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fe567c-af94-4aa1-8060-d6439eb54970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Training 3 backbones with root-level v9 split\n",
      "[b3] Ep01/50 | Tr=0.9795 Va=0.5965 F1=0.9000\n",
      "[b3] Ep02/50 | Tr=0.4846 Va=0.5142 F1=0.9341\n",
      "[b3] Ep03/50 | Tr=0.4035 Va=0.5139 F1=0.9406\n",
      "[b3] Ep04/50 | Tr=0.3805 Va=0.5250 F1=0.9394\n",
      "[b3] Ep05/50 | Tr=0.3695 Va=0.5414 F1=0.9368\n",
      "[b3] Ep06/50 | Tr=0.3583 Va=0.5085 F1=0.9424\n",
      "[b3] Ep07/50 | Tr=0.3508 Va=0.5195 F1=0.9400\n",
      "[b3] Ep08/50 | Tr=0.3500 Va=0.5310 F1=0.9409\n",
      "[b3] Ep09/50 | Tr=0.3445 Va=0.5206 F1=0.9455\n",
      "[b3] Ep10/50 | Tr=0.3440 Va=0.5118 F1=0.9406\n",
      "[b3] Ep11/50 | Tr=0.3405 Va=0.5303 F1=0.9375\n",
      "[b3] Ep12/50 | Tr=0.3393 Va=0.5131 F1=0.9423\n",
      "[b3] Ep13/50 | Tr=0.3411 Va=0.5165 F1=0.9420\n",
      "[b3] Ep14/50 | Tr=0.3353 Va=0.5188 F1=0.9439\n",
      "[b3] Ep15/50 | Tr=0.3365 Va=0.5124 F1=0.9499\n",
      "[b3] Ep16/50 | Tr=0.3354 Va=0.5024 F1=0.9476\n",
      "[b3] Ep17/50 | Tr=0.3313 Va=0.4907 F1=0.9549\n",
      "[b3] Ep18/50 | Tr=0.3290 Va=0.4905 F1=0.9524\n",
      "[b3] Ep19/50 | Tr=0.3335 Va=0.5471 F1=0.9375\n",
      "[b3] Ep20/50 | Tr=0.3335 Va=0.4964 F1=0.9463\n",
      "[b3] Ep21/50 | Tr=0.3289 Va=0.5213 F1=0.9437\n",
      "[b3] Ep22/50 | Tr=0.3287 Va=0.5187 F1=0.9439\n",
      "[b3] Ep23/50 | Tr=0.3341 Va=0.5096 F1=0.9435\n",
      "[b3] Ep24/50 | Tr=0.3280 Va=0.5020 F1=0.9451\n",
      "[b3] Ep25/50 | Tr=0.3307 Va=0.5091 F1=0.9437\n",
      "‚úÖ b3 best F1=0.9549\n",
      "[conv] Ep01/50 | Tr=0.8961 Va=0.4762 F1=0.9340\n",
      "[conv] Ep02/50 | Tr=0.4175 Va=0.4880 F1=0.9377\n",
      "[conv] Ep03/50 | Tr=0.3758 Va=0.4764 F1=0.9543\n",
      "[conv] Ep04/50 | Tr=0.3715 Va=0.5528 F1=0.9159\n",
      "[conv] Ep05/50 | Tr=0.3548 Va=0.5304 F1=0.9457\n",
      "[conv] Ep06/50 | Tr=0.3508 Va=0.5651 F1=0.9260\n",
      "[conv] Ep07/50 | Tr=0.3467 Va=0.5532 F1=0.9326\n",
      "[conv] Ep08/50 | Tr=0.3561 Va=0.5193 F1=0.9378\n",
      "[conv] Ep09/50 | Tr=0.3486 Va=0.5619 F1=0.9252\n",
      "[conv] Ep10/50 | Tr=0.3358 Va=0.5133 F1=0.9409\n",
      "[conv] Ep11/50 | Tr=0.3534 Va=0.4942 F1=0.9484\n",
      "‚úÖ conv best F1=0.9543\n",
      "[vit] Ep01/50 | Tr=0.9007 Va=0.6301 F1=0.8671\n",
      "[vit] Ep02/50 | Tr=0.4879 Va=0.5316 F1=0.9018\n",
      "[vit] Ep03/50 | Tr=0.4528 Va=0.5368 F1=0.9115\n",
      "[vit] Ep04/50 | Tr=0.4328 Va=0.5519 F1=0.9026\n",
      "[vit] Ep05/50 | Tr=0.3989 Va=0.5582 F1=0.9081\n",
      "[vit] Ep06/50 | Tr=0.4139 Va=0.5789 F1=0.9057\n",
      "[vit] Ep07/50 | Tr=0.4011 Va=0.5315 F1=0.9203\n",
      "[vit] Ep08/50 | Tr=0.3995 Va=0.6213 F1=0.9059\n",
      "[vit] Ep09/50 | Tr=0.3959 Va=0.5470 F1=0.9268\n",
      "[vit] Ep10/50 | Tr=0.3723 Va=0.5764 F1=0.9096\n",
      "[vit] Ep11/50 | Tr=0.3940 Va=0.5381 F1=0.9211\n",
      "[vit] Ep12/50 | Tr=0.3816 Va=0.5577 F1=0.9157\n",
      "[vit] Ep13/50 | Tr=0.3741 Va=0.6176 F1=0.8982\n",
      "[vit] Ep14/50 | Tr=0.3852 Va=0.5599 F1=0.9283\n",
      "[vit] Ep15/50 | Tr=0.3629 Va=0.5734 F1=0.9057\n",
      "[vit] Ep16/50 | Tr=0.3771 Va=0.5714 F1=0.9225\n",
      "[vit] Ep17/50 | Tr=0.3753 Va=0.5989 F1=0.9112\n",
      "[vit] Ep18/50 | Tr=0.3790 Va=0.5996 F1=0.9023\n",
      "[vit] Ep19/50 | Tr=0.3598 Va=0.6021 F1=0.9092\n",
      "[vit] Ep20/50 | Tr=0.3650 Va=0.5267 F1=0.9208\n",
      "[vit] Ep21/50 | Tr=0.3578 Va=0.5661 F1=0.9180\n",
      "[vit] Ep22/50 | Tr=0.3689 Va=0.5963 F1=0.9082\n",
      "‚úÖ vit best F1=0.9283\n",
      "\n",
      "üìè Temperature scaling\n",
      "\n",
      "‚öñÔ∏è Searching best ensemble weights...\n",
      "Best holdout F1=0.9599 | weights: b3=0.50, conv=0.35, vit=0.15\n",
      "\n",
      "üîÆ Inference with 4-way TTA\n",
      "\n",
      "‚úÖ Saved submission ‚Üí ./runs_v9_holdout/submission_v9_F0.9599.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# Main\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üöÄ Training 3 backbones with root-level v9 split\")\n",
    "    b3_p, ho_y = train_backbone(\"b3\", train_df, hold_df)\n",
    "    conv_p, _ = train_backbone(\"conv\", train_df, hold_df)\n",
    "    vit_p, _ = train_backbone(\"vit\", train_df, hold_df)\n",
    "\n",
    "    print(\"\\nüìè Temperature scaling\")\n",
    "    T_b3, T_conv, T_vit = fit_temperature(b3_p, ho_y), fit_temperature(conv_p, ho_y), fit_temperature(vit_p, ho_y)\n",
    "    b3_p, conv_p, vit_p = temp_scale(b3_p, T_b3), temp_scale(conv_p, T_conv), temp_scale(vit_p, T_vit)\n",
    "\n",
    "    print(\"\\n‚öñÔ∏è Searching best ensemble weights...\")\n",
    "    (w_b3, w_conv, w_vit), best_f1 = search_weights(b3_p, conv_p, vit_p, ho_y)\n",
    "    print(f\"Best holdout F1={best_f1:.4f} | weights: b3={w_b3:.2f}, conv={w_conv:.2f}, vit={w_vit:.2f}\")\n",
    "\n",
    "    sub = pd.read_csv(SUB_CSV)\n",
    "    sub[\"ID\"] = sub[\"ID\"].apply(lambda x: x if x.endswith(\".jpg\") else f\"{x}.jpg\")\n",
    "    test_paths = [os.path.join(TEST_IMG_V8, f) for f in sub[\"ID\"]]\n",
    "\n",
    "    print(\"\\nüîÆ Inference with 4-way TTA\")\n",
    "    b3_test = infer_tta(\"b3\", f\"{OUT_DIR}/models/b3_best.pt\", test_paths)\n",
    "    conv_test = infer_tta(\"conv\", f\"{OUT_DIR}/models/conv_best.pt\", test_paths)\n",
    "    vit_test = infer_tta(\"vit\", f\"{OUT_DIR}/models/vit_best.pt\", test_paths)\n",
    "\n",
    "    save_npz(f\"{OUT_DIR}/test_probs/b3_test_probs.npz\", b3_test)\n",
    "    save_npz(f\"{OUT_DIR}/test_probs/conv_test_probs.npz\", conv_test)\n",
    "    save_npz(f\"{OUT_DIR}/test_probs/vit_test_probs.npz\", vit_test)\n",
    "\n",
    "    mix = row_normalize(w_b3*b3_test + w_conv*conv_test + w_vit*vit_test)\n",
    "    preds = mix.argmax(1)\n",
    "    out = pd.DataFrame({\"ID\": sub[\"ID\"], \"target\": preds})\n",
    "    out_name = f\"{OUT_DIR}/submission_v9_F{best_f1:.4f}.csv\"\n",
    "    out.to_csv(out_name, index=False)\n",
    "    print(f\"\\n‚úÖ Saved submission ‚Üí {out_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf6042-3eac-483b-ab1f-ba4de5438caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e4072f-a11c-4061-92b0-119fd1862871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56b4e4a-70d6-4d90-a712-012179f39c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
