{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8392ddee-b0dc-41f8-b4f3-3c68a00a2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§  Toss Document Classification: v10_b4_vit_ensemble (Advanced)\n",
    "# ============================================================\n",
    "\n",
    "import os, random, copy, cv2, timm, torch\n",
    "import pandas as pd, numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm import tqdm\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22c4ff63-2fa7-4d38-9ef1-8122bc1b20cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0ï¸âƒ£ Global Config\n",
    "# ============================================================\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BASE_DIR = \"/data/ephemeral/home/data\"\n",
    "TRAIN_META = os.path.join(BASE_DIR, \"meta_stage0_10_1_train_v10.csv\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, \"processed\", \"stage0_10_1_test_v10\")\n",
    "SAMPLE_SUB = os.path.join(BASE_DIR, \"raw\", \"sample_submission.csv\")\n",
    "OUT_DIR = \"./runs_v10_b4_vit_ensemble\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SPECIAL_CLASSES = {3, 7, 14}\n",
    "\n",
    "# --- EfficientNet-B4 ---\n",
    "CFG_B4 = dict(\n",
    "    model_name=\"tf_efficientnet_b4_ns\",\n",
    "    num_classes=17,\n",
    "    img_size=380,\n",
    "    batch_size=32,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=50,\n",
    "    patience=10,\n",
    "    valid_ratio=0.8,\n",
    "    num_workers=4,\n",
    "    tta_times=20,\n",
    ")\n",
    "\n",
    "# --- ViT (for ensemble) ---\n",
    "CFG_VIT = dict(\n",
    "    model_name=\"vit_base_patch16_384\",\n",
    "    num_classes=17,\n",
    "    img_size=384,\n",
    "    batch_size=16,\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-4,\n",
    "    epochs=40,\n",
    "    patience=8,\n",
    "    valid_ratio=0.8,\n",
    "    num_workers=4,\n",
    "    tta_times=20,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e1cde65-231d-4623-ad16-b5ca23ef5340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1ï¸âƒ£ Dataset\n",
    "# ============================================================\n",
    "class V10ImageDataset(Dataset):\n",
    "    def __init__(self, csv_path, transform=None, oversample=False):\n",
    "        df = pd.read_csv(csv_path)\n",
    "        if oversample:\n",
    "            df = self._oversample(df)\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def _oversample(self, df):\n",
    "        factors = {3: 2, 7: 2, 14: 3}\n",
    "        parts = [df]\n",
    "        for cls, f in factors.items():\n",
    "            sub = df[df[\"target\"] == cls]\n",
    "            if len(sub) > 0 and f > 1:\n",
    "                parts.append(sub.loc[sub.index.repeat(f - 1)])\n",
    "        out = pd.concat(parts, axis=0).reset_index(drop=True)\n",
    "        print(\"âœ… Oversample ì™„ë£Œ:\", {k: (out['target'] == k).sum() for k in factors})\n",
    "        return out\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = cv2.imread(row[\"filepath\"])\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        label = row[\"target\"]\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)[\"image\"]\n",
    "        return img, int(label)\n",
    "\n",
    "\n",
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, sample_csv, test_dir, transform):\n",
    "        if isinstance(sample_csv, str):\n",
    "            self.df = pd.read_csv(sample_csv)\n",
    "        elif isinstance(sample_csv, pd.DataFrame):\n",
    "            self.df = sample_csv.copy()\n",
    "        else:\n",
    "            raise ValueError(\"âŒ sample_csv must be path or DataFrame\")\n",
    "\n",
    "        self.test_dir = test_dir\n",
    "        self.transform = transform\n",
    "        self.df[\"ID\"] = self.df[\"ID\"].apply(lambda x: x if str(x).endswith(\".jpg\") else f\"{x}.jpg\")\n",
    "\n",
    "    def __len__(self): return len(self.df)\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.df.iloc[idx][\"ID\"]\n",
    "        path = os.path.join(self.test_dir, img_id)\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = self.transform(image=img)[\"image\"]\n",
    "        return img, img_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc65bcb0-fa55-4f71-b653-28a84781a63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2ï¸âƒ£ Transform (Noise ì¤‘ì‹¬ TTA í¬í•¨)\n",
    "# ============================================================\n",
    "def get_transform(img_size, tta=False):\n",
    "    base = [\n",
    "        A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
    "                      border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255)),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406),\n",
    "                    std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    "    if not tta:\n",
    "        return A.Compose([\n",
    "            A.RandomRotate90(p=0.5),\n",
    "            A.OneOf([A.HorizontalFlip(p=0.5),\n",
    "                     A.VerticalFlip(p=0.5)], p=0.5),\n",
    "            A.RandomBrightnessContrast(p=0.3),\n",
    "            A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
    "            A.MotionBlur(p=0.2),\n",
    "            A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
    "            A.MedianBlur(blur_limit=3, p=0.2),\n",
    "        ] + base)\n",
    "    else:\n",
    "        return A.Compose([\n",
    "            A.RandomRotate90(p=1.0),\n",
    "            A.OneOf([A.HorizontalFlip(p=0.5),\n",
    "                     A.VerticalFlip(p=0.5)], p=0.5),\n",
    "            A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
    "            A.MotionBlur(p=0.2),\n",
    "        ] + base)\n",
    "\n",
    "# ============================================================\n",
    "# 3ï¸âƒ£ Train / Eval / Infer\n",
    "# ============================================================\n",
    "def create_model(model_name, num_classes, drop=0.2):\n",
    "    model = timm.create_model(model_name, pretrained=True,\n",
    "                              num_classes=num_classes, drop_rate=drop)\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, scaler):\n",
    "    model.train(); total_loss=0; preds=[]; tgts=[]\n",
    "    for imgs, lbls in tqdm(loader, desc=\"[Train]\", leave=False):\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(imgs); loss = criterion(out, lbls)\n",
    "        scaler.scale(loss).backward(); scaler.step(optimizer); scaler.update()\n",
    "        total_loss += loss.item()\n",
    "        preds += out.argmax(1).cpu().tolist(); tgts += lbls.cpu().tolist()\n",
    "    return total_loss/len(loader), accuracy_score(tgts,preds), f1_score(tgts,preds,average='macro')\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_one_epoch(model, loader, criterion):\n",
    "    model.eval(); total_loss=0; preds=[]; tgts=[]\n",
    "    for imgs, lbls in tqdm(loader, desc=\"[Valid]\", leave=False):\n",
    "        imgs, lbls = imgs.to(device), lbls.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = model(imgs); loss = criterion(out, lbls)\n",
    "        total_loss += loss.item()\n",
    "        preds += out.argmax(1).cpu().tolist(); tgts += lbls.cpu().tolist()\n",
    "    return total_loss/len(loader), accuracy_score(tgts,preds), f1_score(tgts,preds,average='macro')\n",
    "\n",
    "@torch.no_grad()\n",
    "def infer_probs(model, loader):\n",
    "    model.eval(); all_probs=[]; all_ids=[]\n",
    "    for imgs, ids in tqdm(loader, desc=\"[Infer]\", leave=False):\n",
    "        imgs = imgs.to(device)\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = F.softmax(model(imgs), dim=1)\n",
    "        all_probs.append(out.cpu().numpy()); all_ids.extend(ids)\n",
    "    return np.concatenate(all_probs), all_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2fbc8e8-dec2-4470-bef3-ac29cc59b80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4ï¸âƒ£ Train Loop\n",
    "# ============================================================\n",
    "def train_loop(cfg, train_ds, valid_ds, model_name, model_tag):\n",
    "    train_loader = DataLoader(train_ds, batch_size=cfg[\"batch_size\"], shuffle=True,\n",
    "                              num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "    valid_loader = DataLoader(valid_ds, batch_size=cfg[\"batch_size\"], shuffle=False,\n",
    "                              num_workers=cfg[\"num_workers\"], pin_memory=True)\n",
    "\n",
    "    model = create_model(model_name, cfg[\"num_classes\"])\n",
    "    weights = torch.tensor([1.5 if i in [3,7,14] else 1.0 for i in range(cfg[\"num_classes\"])],\n",
    "                           dtype=torch.float32).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"],\n",
    "                                  weight_decay=cfg[\"weight_decay\"])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg[\"epochs\"], eta_min=1e-6)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    best_f1, counter = -1, 0\n",
    "    best_path = os.path.join(OUT_DIR, f\"model_{model_tag}_best.pt\")\n",
    "\n",
    "    for e in range(1, cfg[\"epochs\"]+1):\n",
    "        print(f\"\\n==== [{model_tag}] Epoch {e}/{cfg['epochs']} ====\")\n",
    "        tr_l, tr_a, tr_f = train_one_epoch(model, train_loader, criterion, optimizer, scaler)\n",
    "        va_l, va_a, va_f = eval_one_epoch(model, valid_loader, criterion)\n",
    "        scheduler.step()\n",
    "        print(f\"[Train] loss={tr_l:.4f} acc={tr_a:.4f} f1={tr_f:.4f}\")\n",
    "        print(f\"[Valid] loss={va_l:.4f} acc={va_a:.4f} f1={va_f:.4f}\")\n",
    "        if va_f > best_f1:\n",
    "            best_f1 = va_f; counter = 0\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"âœ… Best updated: F1={best_f1:.5f}\")\n",
    "        else:\n",
    "            counter += 1\n",
    "            print(f\"â³ No improve ({counter}/{cfg['patience']})\")\n",
    "            if counter >= cfg[\"patience\"]:\n",
    "                print(\"ðŸ›‘ Early stop\"); break\n",
    "    return best_path, best_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d82122ae-83d0-4cb4-90aa-1da086192f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 5ï¸âƒ£ Inference (b4 + vit soft voting)\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def ensemble_infer(b4_ckpt, vit_ckpt):\n",
    "    print(\"\\nðŸ”„ Ensemble Inference ì‹œìž‘\")\n",
    "    models_cfg = [\n",
    "        (CFG_B4, b4_ckpt),\n",
    "        (CFG_VIT, vit_ckpt),\n",
    "    ]\n",
    "    model_probs = []\n",
    "\n",
    "    for cfg, ckpt in models_cfg:\n",
    "        model = create_model(cfg[\"model_name\"], cfg[\"num_classes\"])\n",
    "        model.load_state_dict(torch.load(ckpt))\n",
    "        model.eval()\n",
    "\n",
    "        base_ds = TestImageDataset(SAMPLE_SUB, TEST_DIR, get_transform(cfg[\"img_size\"]))\n",
    "        base_loader = DataLoader(base_ds, batch_size=cfg[\"batch_size\"], shuffle=False)\n",
    "        probs, ids = infer_probs(model, base_loader)\n",
    "\n",
    "        tta_sum = np.zeros_like(probs)\n",
    "        for i in range(cfg[\"tta_times\"]):\n",
    "            print(f\"[{cfg['model_name']}] TTA round {i+1}/{cfg['tta_times']}\")\n",
    "            tta_ds = TestImageDataset(SAMPLE_SUB, TEST_DIR, get_transform(cfg[\"img_size\"], tta=True))\n",
    "            tta_loader = DataLoader(tta_ds, batch_size=cfg[\"batch_size\"], shuffle=False)\n",
    "            tta_sum += infer_probs(model, tta_loader)[0]\n",
    "        final_probs = (probs + tta_sum / cfg[\"tta_times\"]) / 2\n",
    "        model_probs.append(final_probs)\n",
    "\n",
    "    # âœ… Soft voting (ìžë™ ê°€ì¤‘ì¹˜ ê³„ì‚°)\n",
    "    corr = np.corrcoef(model_probs[0].ravel(), model_probs[1].ravel())[0,1]\n",
    "    w1, w2 = (1-corr), (1+corr)\n",
    "    print(f\"ðŸ“Š Auto ensemble weights â†’ b4:{w1:.3f}, vit:{w2:.3f}\")\n",
    "\n",
    "    final = (w1*model_probs[0] + w2*model_probs[1]) / (w1 + w2)\n",
    "    preds = final.argmax(1)\n",
    "\n",
    "    out = pd.DataFrame({\"ID\": ids, \"target\": preds})\n",
    "    path = os.path.join(OUT_DIR, \"submission_v13_b4_vit.csv\")\n",
    "    out.to_csv(path, index=False)\n",
    "    print(f\"âœ… ê²°ê³¼ ì €ìž¥: {path}\")\n",
    "    return path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d1cc2ab-6996-4300-84b1-c012211bd902",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_437905/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_437905/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_437905/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_437905/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Oversample ì™„ë£Œ: {3: np.int64(12672), 7: np.int64(12928), 14: np.int64(9792)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_437905/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_437905/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_437905/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_437905/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== [b4] Epoch 1/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.2565 acc=0.9186 f1=0.9333\n",
      "[Valid] loss=0.0358 acc=0.9886 f1=0.9908\n",
      "âœ… Best updated: F1=0.99077\n",
      "\n",
      "==== [b4] Epoch 2/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0533 acc=0.9837 f1=0.9865\n",
      "[Valid] loss=0.0378 acc=0.9897 f1=0.9924\n",
      "âœ… Best updated: F1=0.99243\n",
      "\n",
      "==== [b4] Epoch 3/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0351 acc=0.9892 f1=0.9910\n",
      "[Valid] loss=0.0237 acc=0.9936 f1=0.9948\n",
      "âœ… Best updated: F1=0.99481\n",
      "\n",
      "==== [b4] Epoch 4/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0247 acc=0.9926 f1=0.9936\n",
      "[Valid] loss=0.0170 acc=0.9942 f1=0.9948\n",
      "âœ… Best updated: F1=0.99481\n",
      "\n",
      "==== [b4] Epoch 5/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0201 acc=0.9942 f1=0.9950\n",
      "[Valid] loss=0.0116 acc=0.9961 f1=0.9964\n",
      "âœ… Best updated: F1=0.99644\n",
      "\n",
      "==== [b4] Epoch 6/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0167 acc=0.9951 f1=0.9959\n",
      "[Valid] loss=0.0124 acc=0.9970 f1=0.9978\n",
      "âœ… Best updated: F1=0.99777\n",
      "\n",
      "==== [b4] Epoch 7/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0148 acc=0.9956 f1=0.9962\n",
      "[Valid] loss=0.0072 acc=0.9978 f1=0.9982\n",
      "âœ… Best updated: F1=0.99820\n",
      "\n",
      "==== [b4] Epoch 8/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0108 acc=0.9966 f1=0.9968\n",
      "[Valid] loss=0.0058 acc=0.9982 f1=0.9984\n",
      "âœ… Best updated: F1=0.99836\n",
      "\n",
      "==== [b4] Epoch 9/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0104 acc=0.9970 f1=0.9973\n",
      "[Valid] loss=0.0037 acc=0.9987 f1=0.9989\n",
      "âœ… Best updated: F1=0.99886\n",
      "\n",
      "==== [b4] Epoch 10/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0075 acc=0.9977 f1=0.9979\n",
      "[Valid] loss=0.0052 acc=0.9985 f1=0.9985\n",
      "â³ No improve (1/10)\n",
      "\n",
      "==== [b4] Epoch 11/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0087 acc=0.9974 f1=0.9976\n",
      "[Valid] loss=0.0064 acc=0.9984 f1=0.9986\n",
      "â³ No improve (2/10)\n",
      "\n",
      "==== [b4] Epoch 12/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0074 acc=0.9980 f1=0.9983\n",
      "[Valid] loss=0.0081 acc=0.9978 f1=0.9980\n",
      "â³ No improve (3/10)\n",
      "\n",
      "==== [b4] Epoch 13/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0076 acc=0.9980 f1=0.9982\n",
      "[Valid] loss=0.0063 acc=0.9983 f1=0.9984\n",
      "â³ No improve (4/10)\n",
      "\n",
      "==== [b4] Epoch 14/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0061 acc=0.9983 f1=0.9985\n",
      "[Valid] loss=0.0016 acc=0.9994 f1=0.9995\n",
      "âœ… Best updated: F1=0.99950\n",
      "\n",
      "==== [b4] Epoch 15/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0047 acc=0.9985 f1=0.9986\n",
      "[Valid] loss=0.0021 acc=0.9993 f1=0.9995\n",
      "âœ… Best updated: F1=0.99950\n",
      "\n",
      "==== [b4] Epoch 16/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0046 acc=0.9988 f1=0.9990\n",
      "[Valid] loss=0.0015 acc=0.9994 f1=0.9995\n",
      "â³ No improve (1/10)\n",
      "\n",
      "==== [b4] Epoch 17/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0036 acc=0.9988 f1=0.9991\n",
      "[Valid] loss=0.0078 acc=0.9977 f1=0.9978\n",
      "â³ No improve (2/10)\n",
      "\n",
      "==== [b4] Epoch 18/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0042 acc=0.9988 f1=0.9988\n",
      "[Valid] loss=0.0013 acc=0.9996 f1=0.9997\n",
      "âœ… Best updated: F1=0.99968\n",
      "\n",
      "==== [b4] Epoch 19/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0027 acc=0.9992 f1=0.9993\n",
      "[Valid] loss=0.0031 acc=0.9992 f1=0.9993\n",
      "â³ No improve (1/10)\n",
      "\n",
      "==== [b4] Epoch 20/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0035 acc=0.9989 f1=0.9990\n",
      "[Valid] loss=0.0029 acc=0.9990 f1=0.9991\n",
      "â³ No improve (2/10)\n",
      "\n",
      "==== [b4] Epoch 21/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0027 acc=0.9993 f1=0.9993\n",
      "[Valid] loss=0.0023 acc=0.9995 f1=0.9996\n",
      "â³ No improve (3/10)\n",
      "\n",
      "==== [b4] Epoch 22/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0016 acc=0.9996 f1=0.9996\n",
      "[Valid] loss=0.0021 acc=0.9996 f1=0.9997\n",
      "â³ No improve (4/10)\n",
      "\n",
      "==== [b4] Epoch 23/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0025 acc=0.9993 f1=0.9994\n",
      "[Valid] loss=0.0051 acc=0.9990 f1=0.9993\n",
      "â³ No improve (5/10)\n",
      "\n",
      "==== [b4] Epoch 24/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0020 acc=0.9994 f1=0.9995\n",
      "[Valid] loss=0.0008 acc=0.9997 f1=0.9997\n",
      "âœ… Best updated: F1=0.99973\n",
      "\n",
      "==== [b4] Epoch 25/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0016 acc=0.9995 f1=0.9995\n",
      "[Valid] loss=0.0013 acc=0.9997 f1=0.9997\n",
      "â³ No improve (1/10)\n",
      "\n",
      "==== [b4] Epoch 26/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0011 acc=0.9997 f1=0.9997\n",
      "[Valid] loss=0.0028 acc=0.9994 f1=0.9994\n",
      "â³ No improve (2/10)\n",
      "\n",
      "==== [b4] Epoch 27/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0018 acc=0.9995 f1=0.9996\n",
      "[Valid] loss=0.0005 acc=0.9997 f1=0.9998\n",
      "âœ… Best updated: F1=0.99975\n",
      "\n",
      "==== [b4] Epoch 28/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0005 acc=0.9998 f1=0.9999\n",
      "[Valid] loss=0.0024 acc=0.9996 f1=0.9997\n",
      "â³ No improve (1/10)\n",
      "\n",
      "==== [b4] Epoch 29/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0010 acc=0.9997 f1=0.9997\n",
      "[Valid] loss=0.0008 acc=0.9997 f1=0.9997\n",
      "â³ No improve (2/10)\n",
      "\n",
      "==== [b4] Epoch 30/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0005 acc=0.9998 f1=0.9998\n",
      "[Valid] loss=0.0004 acc=1.0000 f1=1.0000\n",
      "âœ… Best updated: F1=0.99998\n",
      "\n",
      "==== [b4] Epoch 31/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0003 acc=0.9999 f1=1.0000\n",
      "[Valid] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "â³ No improve (1/10)\n",
      "\n",
      "==== [b4] Epoch 32/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0006 acc=0.9998 f1=0.9998\n",
      "[Valid] loss=0.0007 acc=0.9997 f1=0.9998\n",
      "â³ No improve (2/10)\n",
      "\n",
      "==== [b4] Epoch 33/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0004 acc=0.9999 f1=0.9998\n",
      "[Valid] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "â³ No improve (3/10)\n",
      "\n",
      "==== [b4] Epoch 34/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0008 acc=0.9998 f1=0.9998\n",
      "[Valid] loss=0.0005 acc=0.9999 f1=0.9999\n",
      "â³ No improve (4/10)\n",
      "\n",
      "==== [b4] Epoch 35/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0002 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0008 acc=0.9998 f1=0.9999\n",
      "â³ No improve (5/10)\n",
      "\n",
      "==== [b4] Epoch 36/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0008 acc=0.9997 f1=0.9997\n",
      "â³ No improve (6/10)\n",
      "\n",
      "==== [b4] Epoch 37/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0005 acc=0.9999 f1=0.9999\n",
      "â³ No improve (7/10)\n",
      "\n",
      "==== [b4] Epoch 38/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0001 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0005 acc=0.9999 f1=0.9999\n",
      "â³ No improve (8/10)\n",
      "\n",
      "==== [b4] Epoch 39/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "â³ No improve (9/10)\n",
      "\n",
      "==== [b4] Epoch 40/50 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "â³ No improve (10/10)\n",
      "ðŸ›‘ Early stop\n",
      "\n",
      "==== [vit] Epoch 1/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Input height (380) doesn't match model (384).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     ensemble_infer(b4_ckpt, vit_ckpt)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m v \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(v); v\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m get_transform(CFG_B4[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], tta\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     10\u001b[0m b4_ckpt, f1_b4 \u001b[38;5;241m=\u001b[39m train_loop(CFG_B4, tr, v, CFG_B4[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m vit_ckpt, f1_vit \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG_VIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG_VIT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[ì™„ë£Œ] B4_F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_b4\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, ViT_F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_vit\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m ensemble_infer(b4_ckpt, vit_ckpt)\n",
      "Cell \u001b[0;32mIn[5], line 24\u001b[0m, in \u001b[0;36mtrain_loop\u001b[0;34m(cfg, train_ds, valid_ds, model_name, model_tag)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, cfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 24\u001b[0m     tr_l, tr_a, tr_f \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     va_l, va_a, va_f \u001b[38;5;241m=\u001b[39m eval_one_epoch(model, valid_loader, criterion)\n\u001b[1;32m     26\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, criterion, optimizer, scaler)\u001b[0m\n\u001b[1;32m     46\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 48\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m)\u001b[49m; loss \u001b[38;5;241m=\u001b[39m criterion(out, lbls)\n\u001b[1;32m     49\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(); scaler\u001b[38;5;241m.\u001b[39mstep(optimizer); scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     50\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/timm/models/vision_transformer.py:992\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, attn_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 992\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/timm/models/vision_transformer.py:935\u001b[0m, in \u001b[0;36mVisionTransformer.forward_features\u001b[0;34m(self, x, attn_mask)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor, attn_mask: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    934\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass through feature layers (embeddings, transformer blocks, post-transformer norm).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    936\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_embed(x)\n\u001b[1;32m    937\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_drop(x)\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/timm/layers/patch_embed.py:121\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrict_img_size:\n\u001b[0;32m--> 121\u001b[0m         \u001b[43m_assert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mH\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mInput height (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m) doesn\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt match model (\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_size\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m).\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m         _assert(W \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput width (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mW\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match model (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdynamic_img_pad:\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/torch/__init__.py:2040\u001b[0m, in \u001b[0;36m_assert\u001b[0;34m(condition, message)\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhas_torch_function(\n\u001b[1;32m   2035\u001b[0m     (condition,)\n\u001b[1;32m   2036\u001b[0m ):\n\u001b[1;32m   2037\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(\n\u001b[1;32m   2038\u001b[0m         _assert, (condition,), condition, message\n\u001b[1;32m   2039\u001b[0m     )\n\u001b[0;32m-> 2040\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[0;31mAssertionError\u001b[0m: Input height (380) doesn't match model (384)."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6ï¸âƒ£ Main Routine\n",
    "# ============================================================\n",
    "def main():\n",
    "    full = V10ImageDataset(TRAIN_META, get_transform(CFG_B4[\"img_size\"]), oversample=True)\n",
    "    n = int(len(full) * (1 - CFG_B4[\"valid_ratio\"]))\n",
    "    tr, v = random_split(full, [len(full) - n, n], generator=torch.Generator().manual_seed(SEED))\n",
    "    v = copy.deepcopy(v); v.dataset.transform = get_transform(CFG_B4[\"img_size\"], tta=False)\n",
    "\n",
    "    b4_ckpt, f1_b4 = train_loop(CFG_B4, tr, v, CFG_B4[\"model_name\"], \"b4\")\n",
    "    vit_ckpt, f1_vit = train_loop(CFG_VIT, tr, v, CFG_VIT[\"model_name\"], \"vit\")\n",
    "\n",
    "    print(f\"\\n[ì™„ë£Œ] B4_F1={f1_b4:.4f}, ViT_F1={f1_vit:.4f}\")\n",
    "    ensemble_infer(b4_ckpt, vit_ckpt)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ac59572-ee7b-4e82-a77e-cb1e1afe9f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§© Resume from B4 checkpoint & train ViT + B5 + ensemble\n",
    "# ============================================================\n",
    "def resume_main():\n",
    "    print(\"ðŸš€ Resume mode: b4 ê±´ë„ˆë›°ê³  vit + b5 + ensemble ì‹¤í–‰\")\n",
    "\n",
    "    # 1ï¸âƒ£ b4 ì²´í¬í¬ì¸íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    b4_ckpt = os.path.join(OUT_DIR, \"model_b4_best.pt\")\n",
    "    if not os.path.exists(b4_ckpt):\n",
    "        raise FileNotFoundError(\"âŒ model_b4_best.pt not found. b4 í•™ìŠµì„ ë¨¼ì € ì™„ë£Œí•´ì•¼ í•©ë‹ˆë‹¤!\")\n",
    "\n",
    "    # 2ï¸âƒ£ ViT ì „ìš© ë°ì´í„°ì…‹ (img_size=384)\n",
    "    full_vit = V10ImageDataset(TRAIN_META, get_transform(CFG_VIT[\"img_size\"]), oversample=True)\n",
    "    n_vit = int(len(full_vit) * (1 - CFG_VIT[\"valid_ratio\"]))\n",
    "    tr_vit, v_vit = random_split(full_vit, [len(full_vit) - n_vit, n_vit],\n",
    "                                 generator=torch.Generator().manual_seed(SEED))\n",
    "    v_vit = copy.deepcopy(v_vit)\n",
    "    v_vit.dataset.transform = get_transform(CFG_VIT[\"img_size\"], tta=False)\n",
    "\n",
    "    # 3ï¸âƒ£ ViT í•™ìŠµ\n",
    "    vit_ckpt, f1_vit = train_loop(CFG_VIT, tr_vit, v_vit, CFG_VIT[\"model_name\"], \"vit\")\n",
    "\n",
    "    # 4ï¸âƒ£ (ì„ íƒ) b5 ì„œë¸Œëª¨ë¸ ì¶”ê°€\n",
    "    CFG_B5 = dict(\n",
    "        model_name=\"tf_efficientnet_b5_ns\",\n",
    "        num_classes=17,\n",
    "        img_size=456,\n",
    "        batch_size=16,\n",
    "        lr=3e-4,\n",
    "        weight_decay=1e-4,\n",
    "        epochs=40,\n",
    "        patience=8,\n",
    "        valid_ratio=0.8,\n",
    "        num_workers=4,\n",
    "        tta_times=20,\n",
    "    )\n",
    "\n",
    "    full_b5 = V10ImageDataset(TRAIN_META, get_transform(CFG_B5[\"img_size\"]), oversample=True)\n",
    "    n_b5 = int(len(full_b5) * (1 - CFG_B5[\"valid_ratio\"]))\n",
    "    tr_b5, v_b5 = random_split(full_b5, [len(full_b5) - n_b5, n_b5],\n",
    "                               generator=torch.Generator().manual_seed(SEED))\n",
    "    v_b5 = copy.deepcopy(v_b5)\n",
    "    v_b5.dataset.transform = get_transform(CFG_B5[\"img_size\"], tta=False)\n",
    "\n",
    "    b5_ckpt, f1_b5 = train_loop(CFG_B5, tr_b5, v_b5, CFG_B5[\"model_name\"], \"b5\")\n",
    "\n",
    "    # 5ï¸âƒ£ 3ëª¨ë¸ ì•™ìƒë¸” (b4 + vit + b5)\n",
    "    print(f\"\\n[ì™„ë£Œ] B4âœ“ | ViT_F1={f1_vit:.4f} | B5_F1={f1_b5:.4f}\")\n",
    "    ensemble_3model_infer(b4_ckpt, vit_ckpt, b5_ckpt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3298a0d9-7429-4447-aa58-2a6f8382261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Resume mode: b4 ê±´ë„ˆë›°ê³  vit + b5 + ensemble ì‹¤í–‰\n",
      "âœ… Oversample ì™„ë£Œ: {3: np.int64(12672), 7: np.int64(12928), 14: np.int64(9792)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_501159/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_501159/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== [vit] Epoch 1/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=1.9235 acc=0.3196 f1=0.3077\n",
      "[Valid] loss=1.5707 acc=0.4270 f1=0.4035\n",
      "âœ… Best updated: F1=0.40352\n",
      "\n",
      "==== [vit] Epoch 2/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=1.3912 acc=0.4950 f1=0.4980\n",
      "[Valid] loss=1.3509 acc=0.5111 f1=0.5097\n",
      "âœ… Best updated: F1=0.50973\n",
      "\n",
      "==== [vit] Epoch 3/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=1.1179 acc=0.5962 f1=0.6080\n",
      "[Valid] loss=0.9408 acc=0.6584 f1=0.6691\n",
      "âœ… Best updated: F1=0.66914\n",
      "\n",
      "==== [vit] Epoch 4/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.8635 acc=0.6912 f1=0.7038\n",
      "[Valid] loss=0.7436 acc=0.7314 f1=0.7375\n",
      "âœ… Best updated: F1=0.73753\n",
      "\n",
      "==== [vit] Epoch 5/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.6704 acc=0.7616 f1=0.7724\n",
      "[Valid] loss=0.5880 acc=0.7864 f1=0.8027\n",
      "âœ… Best updated: F1=0.80274\n",
      "\n",
      "==== [vit] Epoch 6/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.5632 acc=0.8004 f1=0.8114\n",
      "[Valid] loss=0.5317 acc=0.8106 f1=0.8204\n",
      "âœ… Best updated: F1=0.82043\n",
      "\n",
      "==== [vit] Epoch 7/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.4850 acc=0.8275 f1=0.8380\n",
      "[Valid] loss=0.4338 acc=0.8450 f1=0.8601\n",
      "âœ… Best updated: F1=0.86008\n",
      "\n",
      "==== [vit] Epoch 8/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.4301 acc=0.8489 f1=0.8591\n",
      "[Valid] loss=0.4057 acc=0.8570 f1=0.8659\n",
      "âœ… Best updated: F1=0.86591\n",
      "\n",
      "==== [vit] Epoch 9/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.3822 acc=0.8653 f1=0.8745\n",
      "[Valid] loss=0.3981 acc=0.8664 f1=0.8742\n",
      "âœ… Best updated: F1=0.87416\n",
      "\n",
      "==== [vit] Epoch 10/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.3431 acc=0.8793 f1=0.8881\n",
      "[Valid] loss=0.3224 acc=0.8851 f1=0.8926\n",
      "âœ… Best updated: F1=0.89262\n",
      "\n",
      "==== [vit] Epoch 11/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.3034 acc=0.8944 f1=0.9020\n",
      "[Valid] loss=0.3132 acc=0.8951 f1=0.9031\n",
      "âœ… Best updated: F1=0.90306\n",
      "\n",
      "==== [vit] Epoch 12/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.2660 acc=0.9078 f1=0.9144\n",
      "[Valid] loss=0.2648 acc=0.9094 f1=0.9164\n",
      "âœ… Best updated: F1=0.91642\n",
      "\n",
      "==== [vit] Epoch 13/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.2330 acc=0.9199 f1=0.9261\n",
      "[Valid] loss=0.2298 acc=0.9197 f1=0.9273\n",
      "âœ… Best updated: F1=0.92730\n",
      "\n",
      "==== [vit] Epoch 14/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.2027 acc=0.9309 f1=0.9362\n",
      "[Valid] loss=0.2158 acc=0.9271 f1=0.9328\n",
      "âœ… Best updated: F1=0.93283\n",
      "\n",
      "==== [vit] Epoch 15/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.1750 acc=0.9403 f1=0.9444\n",
      "[Valid] loss=0.2121 acc=0.9310 f1=0.9367\n",
      "âœ… Best updated: F1=0.93674\n",
      "\n",
      "==== [vit] Epoch 16/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.1532 acc=0.9480 f1=0.9514\n",
      "[Valid] loss=0.1694 acc=0.9441 f1=0.9474\n",
      "âœ… Best updated: F1=0.94743\n",
      "\n",
      "==== [vit] Epoch 17/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.1305 acc=0.9551 f1=0.9582\n",
      "[Valid] loss=0.1621 acc=0.9461 f1=0.9499\n",
      "âœ… Best updated: F1=0.94991\n",
      "\n",
      "==== [vit] Epoch 18/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.1117 acc=0.9619 f1=0.9644\n",
      "[Valid] loss=0.1573 acc=0.9506 f1=0.9549\n",
      "âœ… Best updated: F1=0.95489\n",
      "\n",
      "==== [vit] Epoch 19/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0992 acc=0.9662 f1=0.9680\n",
      "[Valid] loss=0.1214 acc=0.9583 f1=0.9614\n",
      "âœ… Best updated: F1=0.96143\n",
      "\n",
      "==== [vit] Epoch 20/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0853 acc=0.9712 f1=0.9728\n",
      "[Valid] loss=0.1410 acc=0.9546 f1=0.9588\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [vit] Epoch 21/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0717 acc=0.9757 f1=0.9771\n",
      "[Valid] loss=0.1104 acc=0.9631 f1=0.9646\n",
      "âœ… Best updated: F1=0.96465\n",
      "\n",
      "==== [vit] Epoch 22/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0606 acc=0.9794 f1=0.9804\n",
      "[Valid] loss=0.0928 acc=0.9695 f1=0.9705\n",
      "âœ… Best updated: F1=0.97050\n",
      "\n",
      "==== [vit] Epoch 23/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0525 acc=0.9824 f1=0.9833\n",
      "[Valid] loss=0.0968 acc=0.9693 f1=0.9705\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [vit] Epoch 24/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0410 acc=0.9860 f1=0.9866\n",
      "[Valid] loss=0.0891 acc=0.9715 f1=0.9730\n",
      "âœ… Best updated: F1=0.97295\n",
      "\n",
      "==== [vit] Epoch 25/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0347 acc=0.9882 f1=0.9886\n",
      "[Valid] loss=0.0878 acc=0.9748 f1=0.9759\n",
      "âœ… Best updated: F1=0.97585\n",
      "\n",
      "==== [vit] Epoch 26/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0308 acc=0.9898 f1=0.9901\n",
      "[Valid] loss=0.0708 acc=0.9767 f1=0.9771\n",
      "âœ… Best updated: F1=0.97713\n",
      "\n",
      "==== [vit] Epoch 27/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0246 acc=0.9917 f1=0.9920\n",
      "[Valid] loss=0.0842 acc=0.9740 f1=0.9744\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [vit] Epoch 28/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0180 acc=0.9936 f1=0.9938\n",
      "[Valid] loss=0.0667 acc=0.9812 f1=0.9816\n",
      "âœ… Best updated: F1=0.98158\n",
      "\n",
      "==== [vit] Epoch 29/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0163 acc=0.9943 f1=0.9945\n",
      "[Valid] loss=0.0673 acc=0.9811 f1=0.9816\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [vit] Epoch 30/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0128 acc=0.9959 f1=0.9960\n",
      "[Valid] loss=0.0761 acc=0.9796 f1=0.9801\n",
      "â³ No improve (2/8)\n",
      "\n",
      "==== [vit] Epoch 31/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0105 acc=0.9966 f1=0.9969\n",
      "[Valid] loss=0.0567 acc=0.9843 f1=0.9846\n",
      "âœ… Best updated: F1=0.98461\n",
      "\n",
      "==== [vit] Epoch 32/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0082 acc=0.9972 f1=0.9972\n",
      "[Valid] loss=0.0556 acc=0.9858 f1=0.9860\n",
      "âœ… Best updated: F1=0.98603\n",
      "\n",
      "==== [vit] Epoch 33/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0064 acc=0.9980 f1=0.9980\n",
      "[Valid] loss=0.0553 acc=0.9861 f1=0.9863\n",
      "âœ… Best updated: F1=0.98627\n",
      "\n",
      "==== [vit] Epoch 34/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0051 acc=0.9983 f1=0.9983\n",
      "[Valid] loss=0.0526 acc=0.9876 f1=0.9878\n",
      "âœ… Best updated: F1=0.98781\n",
      "\n",
      "==== [vit] Epoch 35/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0036 acc=0.9988 f1=0.9989\n",
      "[Valid] loss=0.0544 acc=0.9866 f1=0.9868\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [vit] Epoch 36/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0030 acc=0.9991 f1=0.9991\n",
      "[Valid] loss=0.0518 acc=0.9881 f1=0.9884\n",
      "âœ… Best updated: F1=0.98842\n",
      "\n",
      "==== [vit] Epoch 37/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0023 acc=0.9992 f1=0.9992\n",
      "[Valid] loss=0.0495 acc=0.9884 f1=0.9887\n",
      "âœ… Best updated: F1=0.98868\n",
      "\n",
      "==== [vit] Epoch 38/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0020 acc=0.9994 f1=0.9995\n",
      "[Valid] loss=0.0498 acc=0.9887 f1=0.9889\n",
      "âœ… Best updated: F1=0.98889\n",
      "\n",
      "==== [vit] Epoch 39/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0019 acc=0.9994 f1=0.9994\n",
      "[Valid] loss=0.0483 acc=0.9890 f1=0.9892\n",
      "âœ… Best updated: F1=0.98923\n",
      "\n",
      "==== [vit] Epoch 40/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_501159/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_501159/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b5_ns to current tf_efficientnet_b5.ns_jft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0019 acc=0.9994 f1=0.9994\n",
      "[Valid] loss=0.0479 acc=0.9884 f1=0.9886\n",
      "â³ No improve (1/8)\n",
      "âœ… Oversample ì™„ë£Œ: {3: np.int64(12672), 7: np.int64(12928), 14: np.int64(9792)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a8d273c31246b1b5fabc1a0c307947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/122M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==== [b5] Epoch 1/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.2467 acc=0.9212 f1=0.9363\n",
      "[Valid] loss=0.0789 acc=0.9788 f1=0.9846\n",
      "âœ… Best updated: F1=0.98456\n",
      "\n",
      "==== [b5] Epoch 2/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0664 acc=0.9798 f1=0.9830\n",
      "[Valid] loss=0.0291 acc=0.9918 f1=0.9937\n",
      "âœ… Best updated: F1=0.99367\n",
      "\n",
      "==== [b5] Epoch 3/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0400 acc=0.9881 f1=0.9900\n",
      "[Valid] loss=0.0136 acc=0.9960 f1=0.9967\n",
      "âœ… Best updated: F1=0.99670\n",
      "\n",
      "==== [b5] Epoch 4/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0281 acc=0.9918 f1=0.9929\n",
      "[Valid] loss=0.0170 acc=0.9952 f1=0.9954\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 5/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0209 acc=0.9937 f1=0.9944\n",
      "[Valid] loss=0.0056 acc=0.9979 f1=0.9982\n",
      "âœ… Best updated: F1=0.99820\n",
      "\n",
      "==== [b5] Epoch 6/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0183 acc=0.9944 f1=0.9950\n",
      "[Valid] loss=0.0114 acc=0.9970 f1=0.9976\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 7/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0145 acc=0.9956 f1=0.9960\n",
      "[Valid] loss=0.0115 acc=0.9969 f1=0.9969\n",
      "â³ No improve (2/8)\n",
      "\n",
      "==== [b5] Epoch 8/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0126 acc=0.9962 f1=0.9965\n",
      "[Valid] loss=0.0097 acc=0.9970 f1=0.9975\n",
      "â³ No improve (3/8)\n",
      "\n",
      "==== [b5] Epoch 9/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0104 acc=0.9969 f1=0.9972\n",
      "[Valid] loss=0.0064 acc=0.9981 f1=0.9983\n",
      "âœ… Best updated: F1=0.99828\n",
      "\n",
      "==== [b5] Epoch 10/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0093 acc=0.9974 f1=0.9976\n",
      "[Valid] loss=0.0044 acc=0.9987 f1=0.9988\n",
      "âœ… Best updated: F1=0.99876\n",
      "\n",
      "==== [b5] Epoch 11/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0081 acc=0.9976 f1=0.9978\n",
      "[Valid] loss=0.0027 acc=0.9993 f1=0.9993\n",
      "âœ… Best updated: F1=0.99934\n",
      "\n",
      "==== [b5] Epoch 12/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0070 acc=0.9979 f1=0.9981\n",
      "[Valid] loss=0.0043 acc=0.9986 f1=0.9988\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 13/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0070 acc=0.9977 f1=0.9979\n",
      "[Valid] loss=0.0039 acc=0.9988 f1=0.9989\n",
      "â³ No improve (2/8)\n",
      "\n",
      "==== [b5] Epoch 14/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0042 acc=0.9990 f1=0.9991\n",
      "[Valid] loss=0.0056 acc=0.9983 f1=0.9984\n",
      "â³ No improve (3/8)\n",
      "\n",
      "==== [b5] Epoch 15/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0048 acc=0.9986 f1=0.9987\n",
      "[Valid] loss=0.0027 acc=0.9992 f1=0.9994\n",
      "âœ… Best updated: F1=0.99935\n",
      "\n",
      "==== [b5] Epoch 16/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0040 acc=0.9987 f1=0.9989\n",
      "[Valid] loss=0.0038 acc=0.9990 f1=0.9992\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 17/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0032 acc=0.9990 f1=0.9991\n",
      "[Valid] loss=0.0014 acc=0.9995 f1=0.9995\n",
      "âœ… Best updated: F1=0.99946\n",
      "\n",
      "==== [b5] Epoch 18/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0030 acc=0.9992 f1=0.9993\n",
      "[Valid] loss=0.0014 acc=0.9996 f1=0.9997\n",
      "âœ… Best updated: F1=0.99967\n",
      "\n",
      "==== [b5] Epoch 19/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0029 acc=0.9992 f1=0.9992\n",
      "[Valid] loss=0.0018 acc=0.9994 f1=0.9995\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 20/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0023 acc=0.9993 f1=0.9994\n",
      "[Valid] loss=0.0017 acc=0.9994 f1=0.9995\n",
      "â³ No improve (2/8)\n",
      "\n",
      "==== [b5] Epoch 21/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0019 acc=0.9994 f1=0.9995\n",
      "[Valid] loss=0.0006 acc=0.9997 f1=0.9997\n",
      "âœ… Best updated: F1=0.99970\n",
      "\n",
      "==== [b5] Epoch 22/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0013 acc=0.9995 f1=0.9996\n",
      "[Valid] loss=0.0015 acc=0.9995 f1=0.9995\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 23/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0012 acc=0.9996 f1=0.9996\n",
      "[Valid] loss=0.0004 acc=0.9998 f1=0.9998\n",
      "âœ… Best updated: F1=0.99984\n",
      "\n",
      "==== [b5] Epoch 24/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0008 acc=0.9998 f1=0.9998\n",
      "[Valid] loss=0.0019 acc=0.9995 f1=0.9996\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 25/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0012 acc=0.9997 f1=0.9997\n",
      "[Valid] loss=0.0005 acc=0.9998 f1=0.9998\n",
      "â³ No improve (2/8)\n",
      "\n",
      "==== [b5] Epoch 26/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0005 acc=0.9998 f1=0.9998\n",
      "[Valid] loss=0.0006 acc=0.9999 f1=0.9999\n",
      "âœ… Best updated: F1=0.99989\n",
      "\n",
      "==== [b5] Epoch 27/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0005 acc=0.9998 f1=0.9998\n",
      "[Valid] loss=0.0021 acc=0.9995 f1=0.9994\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 28/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0003 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0003 acc=0.9999 f1=0.9999\n",
      "âœ… Best updated: F1=0.99990\n",
      "\n",
      "==== [b5] Epoch 29/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0003 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0002 acc=0.9998 f1=0.9998\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 30/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0005 acc=0.9998 f1=0.9999\n",
      "â³ No improve (2/8)\n",
      "\n",
      "==== [b5] Epoch 31/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0003 acc=1.0000 f1=1.0000\n",
      "âœ… Best updated: F1=0.99997\n",
      "\n",
      "==== [b5] Epoch 32/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0004 acc=0.9999 f1=0.9999\n",
      "â³ No improve (1/8)\n",
      "\n",
      "==== [b5] Epoch 33/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "â³ No improve (2/8)\n",
      "\n",
      "==== [b5] Epoch 34/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0000 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "â³ No improve (3/8)\n",
      "\n",
      "==== [b5] Epoch 35/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0000 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0002 acc=0.9999 f1=0.9999\n",
      "â³ No improve (4/8)\n",
      "\n",
      "==== [b5] Epoch 36/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0002 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "â³ No improve (5/8)\n",
      "\n",
      "==== [b5] Epoch 37/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0000 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "â³ No improve (6/8)\n",
      "\n",
      "==== [b5] Epoch 38/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0001 acc=0.9999 f1=0.9999\n",
      "[Valid] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "â³ No improve (7/8)\n",
      "\n",
      "==== [b5] Epoch 39/40 ====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Train] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "[Valid] loss=0.0001 acc=1.0000 f1=1.0000\n",
      "â³ No improve (8/8)\n",
      "ðŸ›‘ Early stop\n",
      "\n",
      "[ì™„ë£Œ] B4âœ“ | ViT_F1=0.9892 | B5_F1=1.0000\n",
      "\n",
      "ðŸ”„ 3-model Ensemble Inference ì‹œìž‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "NameError",
     "evalue": "name 'CFG_B5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# ì‹¤í–‰\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 45\u001b[0m     \u001b[43mresume_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 49\u001b[0m, in \u001b[0;36mresume_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 5ï¸âƒ£ 3ëª¨ë¸ ì•™ìƒë¸” (b4 + vit + b5)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[ì™„ë£Œ] B4âœ“ | ViT_F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_vit\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | B5_F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1_b5\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 49\u001b[0m \u001b[43mensemble_3model_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb4_ckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvit_ckpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb5_ckpt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/py310/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36mensemble_3model_infer\u001b[0;34m(b4_ckpt, vit_ckpt, b5_ckpt)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mno_grad()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mensemble_3model_infer\u001b[39m(b4_ckpt, vit_ckpt, b5_ckpt):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ”„ 3-model Ensemble Inference ì‹œìž‘\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     models_cfg \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m         (CFG_B4, b4_ckpt),\n\u001b[1;32m     10\u001b[0m         (CFG_VIT, vit_ckpt),\n\u001b[0;32m---> 11\u001b[0m         (\u001b[43mCFG_B5\u001b[49m, b5_ckpt),\n\u001b[1;32m     12\u001b[0m     ]\n\u001b[1;32m     13\u001b[0m     model_probs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cfg, ckpt \u001b[38;5;129;01min\u001b[39;00m models_cfg:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CFG_B5' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================\n",
    "# 3-model Ensemble with TTA\n",
    "# ============================================================\n",
    "@torch.no_grad()\n",
    "def ensemble_3model_infer(b4_ckpt, vit_ckpt, b5_ckpt):\n",
    "    print(\"\\nðŸ”„ 3-model Ensemble Inference ì‹œìž‘\")\n",
    "\n",
    "    models_cfg = [\n",
    "        (CFG_B4, b4_ckpt),\n",
    "        (CFG_VIT, vit_ckpt),\n",
    "        (CFG_B5, b5_ckpt),\n",
    "    ]\n",
    "    model_probs = []\n",
    "\n",
    "    for cfg, ckpt in models_cfg:\n",
    "        model = create_model(cfg[\"model_name\"], cfg[\"num_classes\"])\n",
    "        model.load_state_dict(torch.load(ckpt))\n",
    "        model.eval()\n",
    "\n",
    "        base_ds = TestImageDataset(SAMPLE_SUB, TEST_DIR, get_transform(cfg[\"img_size\"]))\n",
    "        base_loader = DataLoader(base_ds, batch_size=cfg[\"batch_size\"], shuffle=False)\n",
    "        probs, ids = infer_probs(model, base_loader)\n",
    "\n",
    "        tta_sum = np.zeros_like(probs)\n",
    "        for i in range(cfg[\"tta_times\"]):\n",
    "            print(f\"[{cfg['model_name']}] TTA round {i+1}/{cfg['tta_times']}\")\n",
    "            tta_ds = TestImageDataset(SAMPLE_SUB, TEST_DIR, get_transform(cfg[\"img_size\"], tta=True))\n",
    "            tta_loader = DataLoader(tta_ds, batch_size=cfg[\"batch_size\"], shuffle=False)\n",
    "            tta_sum += infer_probs(model, tta_loader)[0]\n",
    "        final_probs = (probs + tta_sum / cfg[\"tta_times\"]) / 2\n",
    "        model_probs.append(final_probs)\n",
    "\n",
    "    # âœ… 3-model Soft voting\n",
    "    final = sum(model_probs) / len(model_probs)\n",
    "    preds = final.argmax(1)\n",
    "    out = pd.DataFrame({\"ID\": ids, \"target\": preds})\n",
    "    path = os.path.join(OUT_DIR, \"submission_v13_b4_vit_b5.csv\")\n",
    "    out.to_csv(path, index=False)\n",
    "    print(f\"âœ… ìµœì¢… ê²°ê³¼ ì €ìž¥: {path}\")\n",
    "    return path\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    resume_main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67c0020c-1094-48e1-bd79-d2d870da43df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ 3-model Ensemble Inference (TTA í¬í•¨) ì‹œìž‘\n",
      "\n",
      "[tf_efficientnet_b4_ns] ì¶”ë¡  ì‹œìž‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b4_ns to current tf_efficientnet_b4.ns_jft_in1k.\n",
      "  model = create_fn(\n",
      "/tmp/ipykernel_501159/446507045.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt))\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_501159/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b4_ns] TTA round 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[vit_base_patch16_384] ì¶”ë¡  ì‹œìž‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/446507045.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt))\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_501159/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[vit_base_patch16_384] TTA round 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/py310/lib/python3.10/site-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b5_ns to current tf_efficientnet_b5.ns_jft_in1k.\n",
      "  model = create_fn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[tf_efficientnet_b5_ns] ì¶”ë¡  ì‹œìž‘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/446507045.py:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt))\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:19: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n",
      "/tmp/ipykernel_501159/1902108288.py:21: UserWarning: Argument(s) 'quality_lower, quality_upper' are not valid for transform ImageCompression\n",
      "  A.ImageCompression(quality_lower=70, quality_upper=100, p=0.2),\n",
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_501159/1902108288.py:6: UserWarning: Argument(s) 'always_apply' are not valid for transform MaxSizeTransform\n",
      "  A.LongestMaxSize(max_size=img_size, always_apply=True),\n",
      "/tmp/ipykernel_501159/1902108288.py:7: UserWarning: Argument(s) 'value' are not valid for transform PadIfNeeded\n",
      "  A.PadIfNeeded(min_height=img_size, min_width=img_size,\n",
      "/tmp/ipykernel_501159/1902108288.py:29: UserWarning: Argument(s) 'var_limit' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 40.0), p=0.3),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tf_efficientnet_b5_ns] TTA round 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Soft Voting ì ìš© ì¤‘...\n",
      "âœ… ìµœì¢… ê²°ê³¼ ì €ìž¥: ./runs_v10_b4_vit_ensemble/submission_v14_b4_vit_b5_infer.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ðŸš€ Inference Only: Use existing B4 / ViT / B5 checkpoints\n",
    "# ============================================================\n",
    "\n",
    "import os, torch, numpy as np, pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "@torch.no_grad()\n",
    "def ensemble_3model_infer_only():\n",
    "    print(\"\\nðŸ”„ 3-model Ensemble Inference (TTA í¬í•¨) ì‹œìž‘\")\n",
    "\n",
    "    # âœ… ì´ë¯¸ í•™ìŠµ ì™„ë£Œëœ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì§€ì •\n",
    "    b4_ckpt = os.path.join(OUT_DIR, \"model_b4_best.pt\")\n",
    "    vit_ckpt = os.path.join(OUT_DIR, \"model_vit_best.pt\")\n",
    "    b5_ckpt = os.path.join(OUT_DIR, \"model_b5_best.pt\")\n",
    "\n",
    "    for p in [b4_ckpt, vit_ckpt, b5_ckpt]:\n",
    "        if not os.path.exists(p):\n",
    "            raise FileNotFoundError(f\"âŒ Checkpoint not found: {p}\")\n",
    "\n",
    "    # âœ… CFG_B5ë¥¼ ì „ì—­ì— ì •ì˜ (ì•ˆë¼ ìžˆë‹¤ë©´)\n",
    "    CFG_B5 = dict(\n",
    "        model_name=\"tf_efficientnet_b5_ns\",\n",
    "        num_classes=17,\n",
    "        img_size=456,\n",
    "        batch_size=16,\n",
    "        lr=3e-4,\n",
    "        weight_decay=1e-4,\n",
    "        epochs=40,\n",
    "        patience=8,\n",
    "        valid_ratio=0.8,\n",
    "        num_workers=4,\n",
    "        tta_times=20,\n",
    "    )\n",
    "\n",
    "    # âœ… ì„¸ ëª¨ë¸ êµ¬ì„±\n",
    "    models_cfg = [\n",
    "        (CFG_B4, b4_ckpt),\n",
    "        (CFG_VIT, vit_ckpt),\n",
    "        (CFG_B5, b5_ckpt),\n",
    "    ]\n",
    "    model_probs = []\n",
    "\n",
    "    # âœ… ê° ëª¨ë¸ë³„ ì¶”ë¡  + TTA\n",
    "    for cfg, ckpt in models_cfg:\n",
    "        print(f\"\\n[{cfg['model_name']}] ì¶”ë¡  ì‹œìž‘\")\n",
    "        model = create_model(cfg[\"model_name\"], cfg[\"num_classes\"])\n",
    "        model.load_state_dict(torch.load(ckpt))\n",
    "        model.eval()\n",
    "\n",
    "        base_ds = TestImageDataset(SAMPLE_SUB, TEST_DIR, get_transform(cfg[\"img_size\"]))\n",
    "        base_loader = DataLoader(base_ds, batch_size=cfg[\"batch_size\"], shuffle=False)\n",
    "        probs, ids = infer_probs(model, base_loader)\n",
    "\n",
    "        tta_sum = np.zeros_like(probs)\n",
    "        for i in range(cfg[\"tta_times\"]):\n",
    "            print(f\"[{cfg['model_name']}] TTA round {i+1}/{cfg['tta_times']}\")\n",
    "            tta_ds = TestImageDataset(SAMPLE_SUB, TEST_DIR, get_transform(cfg[\"img_size\"], tta=True))\n",
    "            tta_loader = DataLoader(tta_ds, batch_size=cfg[\"batch_size\"], shuffle=False)\n",
    "            tta_sum += infer_probs(model, tta_loader)[0]\n",
    "\n",
    "        final_probs = (probs + tta_sum / cfg[\"tta_times\"]) / 2\n",
    "        model_probs.append(final_probs)\n",
    "\n",
    "    # âœ… Soft voting (3-model í‰ê· )\n",
    "    print(\"\\nðŸ“Š Soft Voting ì ìš© ì¤‘...\")\n",
    "    final = sum(model_probs) / len(model_probs)\n",
    "    preds = final.argmax(1)\n",
    "\n",
    "    # âœ… ê²°ê³¼ ì €ìž¥\n",
    "    out = pd.DataFrame({\"ID\": ids, \"target\": preds})\n",
    "    path = os.path.join(OUT_DIR, \"submission_v14_b4_vit_b5_infer.csv\")\n",
    "    out.to_csv(path, index=False)\n",
    "    print(f\"âœ… ìµœì¢… ê²°ê³¼ ì €ìž¥: {path}\")\n",
    "    return path\n",
    "\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    ensemble_3model_infer_only()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4b60c8-c3e9-485f-8f25-47e456643acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py310)",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
